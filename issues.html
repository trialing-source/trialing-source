<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <meta name="description" content="" />
    <meta name="author" content="" />
    <title>Issues</title>
    <script src="https://use.fontawesome.com/releases/v5.15.1/js/all.js" crossorigin="anonymous"></script>
    <!-- Google fonts-->
    <link href="https://fonts.googleapis.com/css?family=Varela+Round" rel="stylesheet" />
    <link href="https://fonts.googleapis.com/css?family=Nunito:200,200i,300,300i,400,400i,600,600i,700,700i,800,800i,900,900i" rel="stylesheet" />
    <!-- Core theme CSS (includes Bootstrap)-->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
    <script src="https://bossanova.uk/jexcel/v4/jexcel.js"></script>
    <script src="https://jsuites.net/v4/jsuites.js"></script>

    <link href="css/styles.css" rel="stylesheet" />
    <link rel="stylesheet" href="https://jsuites.net/v4/jsuites.css" type="text/css" />
    <link rel="stylesheet" href="css/sheet.css">
    <link rel="stylesheet" href="css/excel.css">
    <link rel="stylesheet" href="css/darktheme.css">

    <script src="https://cdn.jsdelivr.net/npm/showdown@1.9.0/dist/showdown.min.js"></script>

</head>

<body>

    <div class="container-fluid">
        <div id="table-wrapper">
            <input type="text" id="myInput" onkeyup="myFunction()" placeholder="Search">
            <div id='test'>
                <div id="spreadsheet"></div>
            </div>

        </div>

        <div class="modal " id="desc_modal" tabindex="-1" role="dialog" aria-labelledby="exampleModalLabel" aria-hidden="true">
            <div class="modal-dialog modal-lg modal-dialog-centered" role="document">
                <div class="modal-content">

                    <div class="modal-body">
                        <div class="container-fluid">
                            <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>

                            <h4 class="modal-title" id='mtitle' style='padding-bottom:40px; text-align: left;'></h4>

                            <div id='mbody'></div>

                        </div>
                    </div>
                    <div class="modal-footer">
                    </div>

                </div>
            </div>
        </div>
        is


        <script>
            function myFunction() {
                // Declare variables
                sp.setData(data_all);
                var input, filter, table, tr, td, i, txtValue, data, found_names;
                input = document.getElementById("myInput");
                data = sp.getData();
                found_names = $.grep(data, function(v) {
                    return v[0].match(input.value) || v[1].match(input.value) || v[2].match(input.value);
                });
                sp.setData(found_names);
            };


            var desc = [
                ["We are missing docstrings for some of the functions that users, for example functions in the following locations:\r\n\r\n* https://github.com/couler-proj/couler/blob/d34a690/couler/core/run_templates.py\r\n* https://github.com/couler-proj/couler/tree/d34a690/couler/core/syntax\r\n\r\nWe should add those missing documentation so it's easier for users to look up. Ideally this would prepare us to work on documentation page and API reference later on."],
                ["As reported in a StackOverflow question/answer: https://stackoverflow.com/a/56641265/130288\r\n\r\nAn adapted version of the asker's minimal test case (which could become a unit test):\r\n\r\n~~~Python\r\nimport numpy as np\r\nfrom gensim.models.keyedvectors import WordEmbeddingsKeyedVectors\r\n\r\nkv = WordEmbeddingsKeyedVectors(vector_size=3)\r\nkv.add(entities=['a', 'b'],\r\n       weights=[np.random.rand(3), np.random.rand(3)])\r\nkv.most_similar('a')  # works\r\n\r\nkv.add(entities=['c'], weights=[np.random.rand(3)])\r\nkv.most_similar('c')  # fails with `IndexError`\r\n~~~\r\n\r\nClearing the `vectors_norm` property (with either `del` or assignment-to-`None`) should be sufficient to trigger re-calculation upon the next `most_similar()`. "],
                ['Implement airy functions including `airy`, `airye`, `ai_zeros`, `bi_zeros`, `itairy`.\r\nlist in https://docs.scipy.org/doc/scipy/reference/special.html#airy-functions.'],
                ["There are a number of empty notebooks. Task here is to find them all, and convert each one to its own backlog ticket. Delete those notebooks and remove references to them from other notebooks. You'll also need to check if any of the text surrounding links needs adjusting."],
                ["We have a model zoo but no documentation on how to load the models from it. We also have the PyTorch Lightning wrapper for training the models but no information on how to use the models afterward.\r\n\r\nIt would be great to provide the following (documentation and if it makes sense helper functions):\r\n\r\n**How to load a model that has been saved by PyTorch Lightning (e.g. I just want to get the ResNet backbone from it)?**\r\n```python\r\n# run lightly from CLI or using the PyTorch Lightning wrapper\r\n...\r\n# now you should have a folder with a checkpoint\r\n# let's load the checkpoint in another script (e.g. to do transfer learning)\r\nckpt = torch.load('my_lightning_checkpoint.pth')\r\nmy_resnet = lightly.models.ResNetGenerator()\r\n\r\n# load checkpoint state dict to my_resnet\r\n... # TODO: how to load ckpt state dict into my_resnet\r\n```\r\n\r\n**How to manually save and load a model?**\r\n```python\r\n# simple example of storing and reading a state dict\r\nbackbone = lightly.models.ResNetGenerator()\r\nsimclr_model = lightly.models.SimCLR(backbone)\r\n\r\n# save weights from backbone\r\ntorch.save({'model': simclr_model.state_dict()}, 'my_checkpoint.pth')\r\n\r\n# load the backbone later (can be in another script)\r\nckpt = torch.load('my_checkpoint.pth'')\r\nbackbone = lightly.models.ResNetGenerator()\r\nbackbone.load_state_dict(ckpt['model'])\r\n```\r\n\r\n"],
                ["### URLS with the issue:\r\n\r\n* https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_param\r\n* https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.log_metric\r\n* https://mlflow.org/docs/latest/python_api/mlflow.html#mlflow.set_tag\r\n\r\n### Description of proposal:\r\n\r\nDocument the maximum value and legal characters for log_param, log_metric and set_tag. Note that log_metric's value is already documented as float.\r\n\r\nTags:\r\n* Apparently there is a 250  character limit for tag keys. See https://github.com/mlflow/mlflow/blob/master/mlflow/utils/validation.py#L31.\r\n* There is a 5000 character limit for tag values. See: https://github.com/mlflow/mlflow/blob/master/mlflow/utils/validation.py#L30.\r\n\r\nSample error messages for set_tag::\r\n* `Tag value 'x...' had length 5001, which exceeded length limit of 250`\r\n* `Tag value 'vv...' had length 5001, which exceeded length limit of 5000`\r\n\r\nHowever, there seems to be no limit to a parameter's key or value.\r\n\r\nMetrics:\r\n* MlflowException: Invalid metric name: '01: running time in mins'. Names may only contain alphanumerics, underscores (_), dashes (-), periods (.), spaces ( ), and slashes (/)\r\n\r\n"],
                ["**Motivation: Why do you think this is important?**\r\nNew user should be able to deploy an EKS cluster, create a bucket and an RDS instance using a launch button and also deploy the EKS overlay\r\n\r\nhttps://aws.amazon.com/blogs/devops/construct-your-own-launch-stack-url/\r\n\r\n**Goal: What should the final outcome look like, ideally?**\r\nOn github page of Flyte there should be a launchstack button\r\n\r\n**Describe alternatives you've considered**\r\nmanual creation\r\n\r\n**Flyte component**\r\n- [ ] Overall\r\n- [x] Flyte Setup and Installation scripts\r\n- [ ] Flyte Documentation\r\n- [ ] Flyte communication (slack/email etc)\r\n- [ ] FlytePropeller\r\n- [ ] FlyteIDL (Flyte specification language)\r\n- [ ] Flytekit (Python SDK)\r\n- [ ] FlyteAdmin (Control Plane service)\r\n- [ ] FlytePlugins\r\n- [ ] DataCatalog \r\n- [ ] FlyteStdlib (common libraries)\r\n- [ ] FlyteConsole (UI)\r\n- [ ] Other\r\n\r\n**Additional context**\r\nNone\r\n\r\n**Is this a blocker for you to adopt Flyte**\r\nNo\r\n"],
                ['`dvc run` contains a hardcoded message for `dvc run` which does not change regardless of whether the `--no-exec` is provided. This message is misleading, as the command is not going to be run if `--no-exec` is present:\r\n\r\nhttps://github.com/iterative/dvc/blob/507879e841aa28bdcc62d238d9f49e218a75c62b/dvc/stage.py#L517-L520'],
                ['Feels like a good thing to add. '],
                ['If you run the `petastorm-generate-metadata.py` script installed via pip the working directory of the script will be the virtualenv bin folder. It will then not be able to find any unischema instances on your current python path.\r\n\r\nWe can fix this by doing something like `sys.path.insert(0, os.getcwd())` within the script'],
                ["## 🚀 Feature\r\n<!-- A clear and concise description of the feature proposal -->\r\nDeprecation of old trainer APIs (e.g., checkpoint_callback) and of EvaluationModel in favor of new APIs (e.g., callbacks) and BoringModel. Take PR  #4820 as an example. \r\nThis issue should be tackled one file at the time to allow better review process (as discussed with @Borda).\r\nNOTE (1): Every test should use default BoringModel class or inherit BoringModel to add specific features (e.g., different optimizer) as discussed with @williamFalcon.\r\n\r\n### Motivation\r\n<!-- Please outline the motivation for the proposal. Is your feature request related to a problem? e.g., I'm always frustrated when [...]. If this is related to another GitHub issue, please link here too -->\r\nCode refactoring, tests code-base will be cleaner and easier to extend/improve. New users can refer to tests as a documentation for pytorch-lightning usage and common practices.\r\n\r\n### Pitch\r\nIn the end, we will base tests only on BoringModel.\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n### Alternatives\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered, if any. -->\r\n\r\n### Additional context\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n"],
                ['Currently, it only is stopped if you explicitly call `stop()` or the heartbeat times out after 60 seconds.'],
                ['## 🚀 Feature\r\n\r\nadd/fix typing in all PL codebase, this will yield in multiple PR as we prefer to split the work into smaller peace\r\n\r\n### Additional context\r\n\r\nin #5021  we introduced a new ignore list so after it is merged, take out a single ignored item and fix typing for that part \r\n> each item + its fix = one PR\r\n\r\n### Sections\r\n\r\n- [ ] `pytorch_lightning.callbacks.*` #7035\r\n- [ ] `pytorch_lightning.core.*`  #7035\r\n- [ ] `pytorch_lightning.accelerators.*`  #7035\r\n- [ ] `pytorch_lightning.loggers.*` #7035\r\n- [ ] `pytorch_lightning.logging.*` #7035\r\n- [ ] `pytorch_lightning.metrics.*` <---| @hassiahk\r\n- [ ] `pytorch_lightning.overrides.*`\r\n- [ ] `pytorch_lightning.profiler.*`\r\n- [ ] `pytorch_lightning.pt_overrides.*`\r\n- [ ] `pytorch_lightning.plugins.*`  #7022\r\n- [ ] `pytorch_lightning.root_module.*`\r\n- [ ] `pytorch_lightning.trainer.*`\r\n- [ ] `pytorch_lightning.distributed.*`\r\n- [ ] `pytorch_lightning.tuner.*`\r\n- [ ] `pytorch_lightning.utilities.*`\r\n- [ ] `pl_examples.* by` <---| @janhenriklambrechts\r\n- [ ] `benchmarks.*`\r\n- [ ] `tests.*`\r\n\r\n_This sections can be split even to smaller, most likely still stay per package/folder_'],
                ["Currently we have the fastText subword embeddings available, but it's not included in the pre-trained word embeddings tutorial which is often the first tutorial people checks out. It would be great to add example usage of fastText subword embeddings and show how it helps representing out of vocabulary words.\r\n\r\nThe usage of fastText subword embeddings is to simply specify `load_ngrams` to True when creating [gluonnlp.embedding.FastText](http://gluon-nlp.mxnet.io/master/api/modules/embedding.html#gluonnlp.embedding.FastText)."],
                ['No description provided.'],
                ["Hi,\r\n\r\nI was training a LDASeqModel on ~40k documents through 20 years (20 time slices in my case) and after 2 days of computation, still didn't finish.\r\n\r\nI realized that only LDAModel is used in this class. Shouldn't be better to use LDAMulticore since it can also handle the case of single core ?\r\n\r\nThanks"],
                ['**Is your feature request related to a current problem? Please describe.**\r\nIn order to create an outlier detection with Prophet, i need the full dataframe that\'s return Prophet\r\n\r\n**Describe proposed solution**\r\nRemove the hardcoded `["yhat"]` from `Prophet.predict` add a variable asking to return just `yhat` or all the predictions: `\'yhat_lower\', \'yhat_upper\', etc..`\r\nhttps://unit8co.github.io/darts/_modules/darts/models/prophet.html#Prophet.predict\r\n\r\n\r\nThanks very much! very useful framework \r\n'],
                ["### Description\r\n\r\nCurrently, when a challenge link from EvalAI is shared users see a generic view of EvalAI homepage. We want the details specific to a challenge to be shown when a link is shared. Here's how it looks currently\r\n\r\n![Screen Shot 2021-03-10 at 6 10 48 PM](https://user-images.githubusercontent.com/16323427/110630939-0741db00-81cc-11eb-9f04-55ff5ecc4bc9.png)\r\n\r\nExpected behavior:\r\n\r\nThe shared link view should show details specific to a challenge."],
                ['If the memory mapped file that plasma holds for the objects is too large for the file system (e.g. /dev/shm), the client will get a SIGBUS signal. We should catch that signal and give a good error message.\r\n\r\nTheoretically this behavior is prevented by checking at startup that there is enough space to hold the file. However, it can happen that other programs write to /dev/shm in the meantime and we run into this error anyways.'],
                ['When running TabularPredictor.fit(), I encounter a BrokenPipeError for some reason.\r\nWhat is causing this?\r\nCould it be due to OOM error?\r\n\r\n\r\n> Fitting model: XGBoost ...\r\n> \t-34.1179\t = Validation root_mean_squared_error score\r\n> \t10.58s\t = Training runtime\r\n> \t0.03s\t = Validation runtime\r\n> Fitting model: NeuralNetMXNet ...\r\n> \t-34.2849\t = Validation root_mean_squared_error score\r\n> \t43.63s\t = Training runtime\r\n> \t0.1s\t = Validation runtime\r\n> Fitting model: NeuralNetFastAI ...\r\n> \t-76.3191\t = Validation root_mean_squared_error score\r\n> \t18.02s\t = Training runtime\r\n> \t0.27s\t = Validation runtime\r\n> Fitting model: LightGBMLarge ...\r\n> \t-33.4557\t = Validation root_mean_squared_error score\r\n> \t18.32s\t = Training runtime\r\n> \t0.04s\t = Validation runtime\r\n> ---------------------------------------------------------------------------\r\n> BrokenPipeError                           Traceback (most recent call last)\r\n> <ipython-input-54-00f3a4482ed7> in <module>\r\n>       3 # from https://auto.gluon.ai/stable/index.html\r\n>       4 # \r\n> ----> 5 predictor = TabularPredictor(label=DEPENDENT_VARIABLE).fit(train_data=train_data)\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\site-packages\\autogluon\\core\\utils\\decorators.py in _call(*args, **kwargs)\r\n>      27         def _call(*args, **kwargs):\r\n>      28             gargs, gkwargs = g(*other_args, *args, **kwargs)\r\n> ---> 29             return f(*gargs, **gkwargs)\r\n>      30         return _call\r\n>      31     return _unpack_inner\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py in fit(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, **kwargs)\r\n>     689         self._learner.fit(X=train_data, X_val=tuning_data, X_unlabeled=unlabeled_data,\r\n>     690                           holdout_frac=holdout_frac, num_bag_folds=num_bag_folds, num_bag_sets=num_bag_sets, num_stack_levels=num_stack_levels,\r\n> --> 691                           hyperparameters=hyperparameters, core_kwargs=core_kwargs, time_limit=time_limit, verbosity=verbosity)\r\n>     692         self._set_post_fit_vars()\r\n>     693 \r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\site-packages\\autogluon\\tabular\\learner\\abstract_learner.py in fit(self, X, X_val, **kwargs)\r\n>     124             raise AssertionError(\'Learner is already fit.\')\r\n>     125         self._validate_fit_input(X=X, X_val=X_val, **kwargs)\r\n> --> 126         return self._fit(X=X, X_val=X_val, **kwargs)\r\n>     127 \r\n>     128     def _fit(self, X: DataFrame, X_val: DataFrame = None, scheduler_options=None, hyperparameter_tune=False,\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py in _fit(self, X, X_val, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, verbosity, **trainer_fit_kwargs)\r\n>      93 \r\n>      94         self.save()\r\n> ---> 95         trainer.fit(X, y, X_val=X_val, y_val=y_val, X_unlabeled=X_unlabeled, holdout_frac=holdout_frac, time_limit=time_limit_trainer, **trainer_fit_kwargs)\r\n>      96         self.save_trainer(trainer=trainer)\r\n>      97         time_end = time.time()\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\site-packages\\autogluon\\tabular\\trainer\\auto_trainer.py in fit(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, feature_prune, holdout_frac, num_stack_levels, core_kwargs, time_limit, **kwargs)\r\n>      50         self._train_multi_and_ensemble(X, y, X_val, y_val, X_unlabeled=X_unlabeled, hyperparameters=hyperparameters,\r\n>      51                                        feature_prune=feature_prune,\r\n> ---> 52                                        num_stack_levels=num_stack_levels, time_limit=time_limit, core_kwargs=core_kwargs)\r\n>      53 \r\n>      54     def get_models_distillation(self, hyperparameters, **kwargs):\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\site-packages\\autogluon\\tabular\\trainer\\abstract_trainer.py in _train_multi_and_ensemble(self, X, y, X_val, y_val, hyperparameters, X_unlabeled, num_stack_levels, time_limit, **kwargs)\r\n>    1290         self._num_cols_train = len(list(X.columns))\r\n>    1291         model_names_fit = self.train_multi_levels(X, y, hyperparameters=hyperparameters, X_val=X_val, y_val=y_val,\r\n> -> 1292                                                   X_unlabeled=X_unlabeled, level_start=1, level_end=num_stack_levels+1, time_limit=time_limit, **kwargs)\r\n>    1293         if len(self.get_model_names()) == 0:\r\n>    1294             raise ValueError(\'AutoGluon did not successfully train any models\')\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\site-packages\\autogluon\\tabular\\trainer\\abstract_trainer.py in train_multi_levels(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, base_model_names, feature_prune, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack)\r\n>     259                 models=hyperparameters, level=level, base_model_names=base_model_names,\r\n>     260                 feature_prune=feature_prune,\r\n> --> 261                 core_kwargs=core_kwargs_level, aux_kwargs=aux_kwargs_level, name_suffix=name_suffix,\r\n>     262             )\r\n>     263             model_names_fit += base_model_names + aux_models\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\site-packages\\autogluon\\tabular\\trainer\\abstract_trainer.py in stack_new_level(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, feature_prune, core_kwargs, aux_kwargs, name_suffix)\r\n>     290             aux_models = self.stack_new_level_aux(X=X, y=y, base_model_names=core_models, level=level+1, **aux_kwargs)\r\n>     291         else:\r\n> --> 292             aux_models = self.stack_new_level_aux(X=X_val, y=y_val, fit=False, base_model_names=core_models, level=level+1, **aux_kwargs)\r\n>     293         return core_models, aux_models\r\n>     294 \r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\site-packages\\autogluon\\tabular\\trainer\\abstract_trainer.py in stack_new_level_aux(self, X, y, base_model_names, level, fit, stack_name, time_limit, name_suffix, get_models_func, check_if_best)\r\n>     367         Auxiliary models never use the original features and only train with the predictions of other models as features.\r\n>     368         """\r\n> --> 369         X_stack_preds = self.get_inputs_to_stacker(X, base_models=base_model_names, fit=fit, use_orig_features=False)\r\n>     370         if self.weight_evaluation:\r\n>     371             X, w = extract_column(X, self.sample_weight)  # TODO: consider redesign with w as separate arg instead of bundled inside X\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\site-packages\\autogluon\\tabular\\trainer\\abstract_trainer.py in get_inputs_to_stacker(self, X, base_models, model_pred_proba_dict, fit, use_orig_features)\r\n>     503             base_models = []\r\n>     504         if not fit:\r\n> --> 505             model_pred_proba_dict = self.get_model_pred_proba_dict(X=X, models=base_models, model_pred_proba_dict=model_pred_proba_dict)\r\n>     506             model_pred_proba_list = [model_pred_proba_dict[model] for model in base_models]\r\n>     507         else:\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\site-packages\\autogluon\\tabular\\trainer\\abstract_trainer.py in get_model_pred_proba_dict(self, X, models, model_pred_proba_dict, model_pred_time_dict, fit, record_pred_time)\r\n>     487                     model_pred_proba_dict[model_name] = model.predict_proba(X, **preprocess_kwargs)\r\n>     488                 else:\r\n> --> 489                     model_pred_proba_dict[model_name] = model.predict_proba(X)\r\n>     490 \r\n>     491             if record_pred_time:\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py in predict_proba(self, X, normalize, **kwargs)\r\n>     456         if normalize is None:\r\n>     457             normalize = self.normalize_pred_probas\r\n> --> 458         y_pred_proba = self._predict_proba(X=X, **kwargs)\r\n>     459         if normalize:\r\n>     460             y_pred_proba = normalize_pred_probas(y_pred_proba, self.problem_type)\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py in _predict_proba(self, X, **kwargs)\r\n>     351             X, cat_names=self.cat_columns.copy(), cont_names=self.cont_columns.copy(), procs=self.procs))\r\n>     352         with progress_disabled_ctx(self.model) as model:\r\n> --> 353             preds, _ = model.get_preds(ds_type=DatasetType.Test)\r\n>     354         if single_row:\r\n>     355             preds = preds[:1, :]\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\site-packages\\fastai\\basic_train.py in get_preds(self, ds_type, activ, with_loss, n_batch, pbar)\r\n>     339         callbacks = [cb(self) for cb in self.callback_fns + listify(defaults.extra_callback_fns)] + listify(self.callbacks)\r\n>     340         return get_preds(self.model, self.dl(ds_type), cb_handler=CallbackHandler(callbacks),\r\n> --> 341                          activ=activ, loss_func=lf, n_batch=n_batch, pbar=pbar)\r\n>     342 \r\n>     343     def pred_batch(self, ds_type:DatasetType=DatasetType.Valid, batch:Tuple=None, reconstruct:bool=False,\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\site-packages\\fastai\\basic_train.py in get_preds(model, dl, pbar, cb_handler, activ, loss_func, n_batch)\r\n>      42     "Tuple of predictions and targets, and optional losses (if `loss_func`) using `dl`, max batches `n_batch`."\r\n>      43     res = [to_float(torch.cat(o).cpu()) for o in\r\n> ---> 44            zip(*validate(model, dl, cb_handler=cb_handler, pbar=pbar, average=False, n_batch=n_batch))]\r\n>      45     if loss_func is not None:\r\n>      46         with NoneReduceOnCPU(loss_func) as lf: res.append(lf(res[0], res[1]))\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\site-packages\\fastai\\basic_train.py in validate(model, dl, loss_func, cb_handler, pbar, average, n_batch)\r\n>      55         val_losses,nums = [],[]\r\n>      56         if cb_handler: cb_handler.set_dl(dl)\r\n> ---> 57         for xb,yb in progress_bar(dl, parent=pbar, leave=(pbar is not None)):\r\n>      58             if cb_handler: xb, yb = cb_handler.on_batch_begin(xb, yb, train=False)\r\n>      59             val_loss = loss_batch(model, xb, yb, loss_func, cb_handler=cb_handler)\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\site-packages\\fastprogress\\fastprogress.py in __iter__(self)\r\n>      45         except Exception as e:\r\n>      46             self.on_interrupt()\r\n> ---> 47             raise e\r\n>      48 \r\n>      49     def update(self, val):\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\site-packages\\fastprogress\\fastprogress.py in __iter__(self)\r\n>      39         if self.total != 0: self.update(0)\r\n>      40         try:\r\n> ---> 41             for i,o in enumerate(self.gen):\r\n>      42                 if i >= self.total: break\r\n>      43                 yield o\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\site-packages\\fastai\\basic_data.py in __iter__(self)\r\n>      73     def __iter__(self):\r\n>      74         "Process and returns items from `DataLoader`."\r\n> ---> 75         for b in self.dl: yield self.proc_batch(b)\r\n>      76 \r\n>      77     @classmethod\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\site-packages\\torch\\utils\\data\\dataloader.py in __iter__(self)\r\n>     353             return self._iterator\r\n>     354         else:\r\n> --> 355             return self._get_iterator()\r\n>     356 \r\n>     357     @property\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\site-packages\\torch\\utils\\data\\dataloader.py in _get_iterator(self)\r\n>     299         else:\r\n>     300             self.check_worker_number_rationality()\r\n> --> 301             return _MultiProcessingDataLoaderIter(self)\r\n>     302 \r\n>     303     @property\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\site-packages\\torch\\utils\\data\\dataloader.py in __init__(self, loader)\r\n>     912             #     before it starts, and __del__ tries to join but will get:\r\n>     913             #     AssertionError: can only join a started process.\r\n> --> 914             w.start()\r\n>     915             self._index_queues.append(index_queue)\r\n>     916             self._workers.append(w)\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\multiprocessing\\process.py in start(self)\r\n>     110                \'daemonic processes are not allowed to have children\'\r\n>     111         _cleanup()\r\n> --> 112         self._popen = self._Popen(self)\r\n>     113         self._sentinel = self._popen.sentinel\r\n>     114         # Avoid a refcycle if the target function holds an indirect\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\multiprocessing\\context.py in _Popen(process_obj)\r\n>     221     @staticmethod\r\n>     222     def _Popen(process_obj):\r\n> --> 223         return _default_context.get_context().Process._Popen(process_obj)\r\n>     224 \r\n>     225 class DefaultContext(BaseContext):\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\multiprocessing\\context.py in _Popen(process_obj)\r\n>     320         def _Popen(process_obj):\r\n>     321             from .popen_spawn_win32 import Popen\r\n> --> 322             return Popen(process_obj)\r\n>     323 \r\n>     324     class SpawnContext(BaseContext):\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\multiprocessing\\popen_spawn_win32.py in __init__(self, process_obj)\r\n>      87             try:\r\n>      88                 reduction.dump(prep_data, to_child)\r\n> ---> 89                 reduction.dump(process_obj, to_child)\r\n>      90             finally:\r\n>      91                 set_spawning_popen(None)\r\n> \r\n> C:\\ProgramData\\Anaconda3\\envs\\my_project\\lib\\multiprocessing\\reduction.py in dump(obj, file, protocol)\r\n>      58 def dump(obj, file, protocol=None):\r\n>      59     \'\'\'Replacement for pickle.dump() using ForkingPickler.\'\'\'\r\n> ---> 60     ForkingPickler(file, protocol).dump(obj)\r\n>      61 \r\n>      62 #\r\n> \r\n> BrokenPipeError: [Errno 32] Broken pipe'],
                ['TensorFlow now has `tf.debugging.assert_shapes` (thanks to GPflow user @bodin-e!), which makes it straightforward to add shape checks for input and output tensors. This brings several advantages:\r\n* it helps in uncovering bugs in our code and gives us more confidence our code is behaving as intended,\r\n* it makes clear _in code_ what shapes our code expects / returns (without relying on shape comments that may easily get out of date with the code itself),\r\n* it gives more helpful error messages to users who supply wrongly-shaped tensors as inputs.\r\n\r\nPR #1219 started adding assert_shapes to parts of the code base, but many are still missing. The following modules have relevant tensorflow code that would probably benefit from a bunch of shape assertions.\r\n\r\n- [ ] conditionals\r\n  - [ ] conditionals - not needed?\r\n  - [ ] mo_conditionals -> #1219 (not 100%)\r\n  - [ ] mo_sample_conditionals\r\n  - [ ] sample_conditionals\r\n  - [ ] uncertain_conditionals\r\n  - [x] util -> #1219\r\n- [ ] covariances\r\n  - ...\r\n- [ ] expectations\r\n  - ...\r\n- [ ] kernels\r\n  - ...\r\n- [x] kullback_leiblers -> #1219\r\n- [ ] likelihoods\r\n- [x] logdensities (only `multivariate_normal`) -> #1219\r\n- [ ] mean_functions\r\n- [ ] models\r\n  - ...\r\n  - e.g. predict_f, predict_y, predict_f_samples, etc.\r\n- [ ] optimizers/natgrad\r\n- [ ] quadrature\r\n- [ ] utilities/ops\r\n\r\nIf you would be willing to help with some of these, please go ahead and open PRs! :)'],
                ['<!--Please include [tune], [rllib], [autoscaler] etc. in the issue title if relevant-->\r\n\r\n### Describe your feature request\r\n\r\nRay (as of v0.7?) used to show useful metadata in the task timeline such as the name of the executing function and some system-level metadata such as task and object IDs. In the latest wheels, this information does not appear.\r\n\r\n![Screenshot from 2020-04-16 10-46-42](https://user-images.githubusercontent.com/2560516/79489114-ae73bd80-7fcf-11ea-9deb-2ff1a15129f6.png)\r\n\r\nThis interface used to show:\r\n- the remote function name on the timeline, e.g., "task:foo" instead of just "task"\r\n- when a task was selected, it would show information such as the task ID\r\n\r\nFrom what I can tell, it looks like this metadata is still being collected ([code](https://github.com/ray-project/ray/blob/master/python/ray/_raylet.pyx#L416)), but it doesn\'t appear in the timeline.\r\n'],
                ['No description provided.'],
                ['The `GroupedPredictor` raises an error (`ValueError: Input contains NaN, infinity or a value too large for dtype(\'float64\').`) even if the `estimator` can handle missing values itself.\r\n\r\n```python\r\nfrom sklego.meta import GroupedPredictor\r\nimport numpy as np\r\nfrom sklearn.pipeline import make_pipeline\r\nfrom sklearn.linear_model import LinearRegression\r\nfrom sklearn.impute import SimpleImputer\r\nfrom sklego.datasets import load_chicken\r\n\r\ndf = load_chicken(as_frame=True)\r\n\r\nX, y = df.drop(columns=\'weight\'),  df[\'weight\']\r\n# create missing value\r\nX.loc[0, \'chick\'] = np.nan\r\nmodel =  make_pipeline(SimpleImputer(), LinearRegression())\r\ngroup_model = GroupedPredictor(model, groups=["diet"])\r\ngroup_model.fit(X,y)\r\n```\r\n\r\nThis could be solved i.e. by exposing parameter `force_all_finite` from sklearn function `check_array` into the `GroupedPredictor`\r\n\r\n'],
                ['- Create a new examples directory at the top-level\r\n- Use the API doc examples to apply Spatial SVD model compression to a PyTorch resnet18 model\r\n\r\nIf you are interested in working on this issue - please indicate via a comment on this issue. It should be possible for us to pair you up with an existing contributor to help you get started.\r\n\r\nFrom a complexity perspective, this ticket is at an easy level.'],
                ['See: https://github.com/automl/auto-sklearn\r\n\r\nNeed more investigation to tell if we integrate with that.'],
                ['## 🚀 Feature\r\n\r\nI think `check_val_every_n_epoch` trainer flag should be removed: `val_check_interval` already contains* all of its functionality.\r\n\r\n\\* The only thing needed would be to interpret `val_check_interval=2.0` as check every two epochs. This is just a straightforward extension of the current functionality'],
                ['By exploiting the callbacks `before_forward` and similar it is very easy to log samples of the training dataset, number of patterns, features statistics and other metrics.\r\n\r\nWe can discuss in here what it could be useful to add. \r\n'],
                ['## 🐛 Bug Report\r\n<!-- A clear and concise description of what the bug is. -->\r\n\r\nApparently AccuracyCallback raises an error when 1 is not in tuple passed to AccuracyCallback as topk_args.\r\n\r\n### How To Reproduce\r\nI ran code snippet from https://catalyst-team.github.io/catalyst/#getting-started on Google Colab while only changing topk_args in AccuracyCallback.\r\n\r\n<!-- If you have a code sample, error messages, stack traces, please provide it here as well --> \r\n\r\n\r\n#### Code sample\r\n```python\r\nimport os\r\nfrom torch import nn, optim\r\nfrom torch.utils.data import DataLoader\r\nfrom catalyst import dl, utils\r\nfrom catalyst.data.transforms import ToTensor\r\nfrom catalyst.contrib.datasets import MNIST\r\n\r\nmodel = nn.Sequential(nn.Flatten(), nn.Linear(28 * 28, 10))\r\ncriterion = nn.CrossEntropyLoss()\r\noptimizer = optim.Adam(model.parameters(), lr=0.02)\r\n\r\nloaders = {\r\n    "train": DataLoader(MNIST(os.getcwd(), train=True, download=True, transform=ToTensor()), batch_size=32),\r\n    "valid": DataLoader(MNIST(os.getcwd(), train=False, download=True, transform=ToTensor()), batch_size=32),\r\n}\r\nrunner = dl.SupervisedRunner(input_key="features", output_key="logits", target_key="targets", loss_key="loss")\r\n# model training\r\nrunner.train(\r\n    model=model,\r\n    criterion=criterion,\r\n    optimizer=optimizer,\r\n    loaders=loaders,\r\n    num_epochs=1,\r\n    callbacks=[\r\n        dl.AccuracyCallback(input_key="logits", target_key="targets", topk_args=(2, 3)),\r\n        # catalyst[ml] required\r\n        dl.ConfusionMatrixCallback(input_key="logits", target_key="targets", num_classes=10),\r\n    ],\r\n    logdir="./logs",\r\n    valid_loader="valid",\r\n    valid_metric="loss",\r\n    minimize_valid_metric=True,\r\n    verbose=True,\r\n    load_best_on_end=True,\r\n)\r\n# model inference\r\nfor prediction in runner.predict_loader(loader=loaders["valid"]):\r\n    assert prediction["logits"].detach().cpu().numpy().shape[-1] == 10\r\n\r\nfeatures_batch = next(iter(loaders["valid"]))[0]\r\n# model stochastic weight averaging\r\nmodel.load_state_dict(utils.get_averaged_weights_by_path_mask(logdir="./logs", path_mask="*.pth"))\r\n# model tracing\r\nutils.trace_model(model=runner.model, batch=features_batch)\r\n# model quantization\r\nutils.quantize_model(model=runner.model)\r\n# model pruning\r\nutils.prune_model(model=runner.model, pruning_fn="l1_unstructured", amount=0.8)\r\n# onnx export\r\nutils.onnx_export(model=runner.model, batch=features_batch, file="./logs/mnist.onnx", verbose=True)\r\n```\r\n\r\n<!-- \r\nIdeally attach a minimal code sample to reproduce the decried issue. \r\nMinimal means having the shortest code but still preserving the bug. \r\nYou could use minimal examples - https://github.com/catalyst-team/catalyst#minimal-examples.\r\n-->\r\n\r\n### Expected behavior\r\nAccuracyCallback should work with any tuple of positive integers.\r\n\r\n\r\n### Environment\r\n\r\n```bash\r\nCatalyst version: 21.03.2\r\nPyTorch version: 1.8.1+cu101\r\nIs debug build: No\r\nCUDA used to build PyTorch: 10.1\r\nTensorFlow version: 2.4.1\r\nTensorBoard version: 2.4.1\r\n\r\nOS: Ubuntu 18.04.5 LTS\r\nGCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\nCMake version: version 3.12.0\r\n\r\nPython version: 3.7\r\nIs CUDA available: No\r\nCUDA runtime version: No CUDA\r\nGPU models and configuration: No CUDA\r\nNvidia driver version: No CUDA\r\ncuDNN version: No CUDA\r\n\r\nVersions of relevant libraries:\r\n[pip3] catalyst==21.3.2\r\n[pip3] numpy==1.19.5\r\n[pip3] tensorboard==2.4.1\r\n[pip3] tensorboard-plugin-wit==1.8.0\r\n[pip3] tensorboardX==2.2\r\n[pip3] tensorflow==2.4.1\r\n[pip3] tensorflow-datasets==4.0.1\r\n[pip3] tensorflow-estimator==2.4.0\r\n[pip3] tensorflow-gcs-config==2.4.0\r\n[pip3] tensorflow-hub==0.11.0\r\n[pip3] tensorflow-metadata==0.29.0\r\n[pip3] tensorflow-probability==0.12.1\r\n[pip3] torch==1.8.1+cu101\r\n[pip3] torchsummary==1.5.1\r\n[pip3] torchtext==0.9.1\r\n[pip3] torchvision==0.9.1+cu101\r\n[conda] Could not collect\r\n```\r\n\r\n\r\n### Additional context\r\nFrom what I understood, bug appears because of this line https://github.com/catalyst-team/catalyst/blob/2ff687e802250772f8614583af933d6613f87788/catalyst/metrics/_accuracy.py#L82 ("01" after "accuracy" in string).\r\n\r\n\r\n### Checklist\r\n- [x] bug description.\r\n- [x] steps to reproduce.\r\n- [x] expected behavior.\r\n- [x] environment.\r\n- [x] code sample / screenshots.\r\n- [x] I know, that I could [join Catalyst slack (#__questions channel)](https://join.slack.com/t/catalyst-team-core/shared_invite/zt-d9miirnn-z86oKDzFMKlMG4fgFdZafw) for issue discussion.\r\n'],
                ["Create a notebook with some environment variables in a cell:\r\n\r\n```\r\nprint(os.getenv('USER', default_value))\r\nprint(os.getenv('LOGNAME', default_value))\r\n```\r\n\r\nAdd node to the pipeline and then go to node properties\r\n\r\n![image](https://user-images.githubusercontent.com/382917/86641482-0519e380-bf90-11ea-8ec4-f811b9574200.png)\r\n\r\n\r\nAdd more environment variables to the same or another cell:\r\n\r\n```\r\nprint(os.getenv('USER', default_value))\r\nprint(os.getenv('LOGNAME', default_value))\r\nprint(os.getenv('CONDA_DEFAULT_ENV', default_value))\r\n```\r\n\r\nSave the notebook, reopen the pipeline and the node properties\r\n\r\n![image](https://user-images.githubusercontent.com/382917/86641774-3eeaea00-bf90-11ea-9756-7ce98e7516d5.png)\r\n\r\nNo changes, this is because we are reading/parsing the env_vars values during node add.\r\n\r\nThis should be fixed by implementing #957 and then integrating on the UI. "],
                ["We should be verbose about the param groups that are added after initialization (since we support wildcards and it may be intransparent which param groups are created from that).\r\n\r\nFor example:\r\n\r\n```python\r\n>>> net = Net(optimizer__param_groups=[('dense*', {'lr': 0.03})])\r\nInitializing module!\r\nSetting param group {'lr': 0.03} for dense0.weight, dense0.bias, dense1.weight, dense1.bias.\r\n```"],
                ['This is likely a silly question, but how are activations meant to be handled between CuDNNLSTM/CuDNNGRU layers? The new CuDNNLSTM and CuDNNGRU layers do not contain an activation= parameter to insert activations between GRU cells, and there is no documentation on how activations interact with these new layers. Should they now be created as separate activation layers? \r\n\r\nOr does the optimization/speedup of these constructs come from not having activations between the layers?   Pointers to documentation I may have missed are always appreciated.   \r\n\r\n\r\nPlease make sure that the boxes below are checked before you submit your issue. If your issue is an implementation question, please ask your question on [StackOverflow](http://stackoverflow.com/questions/tagged/keras) or [join the Keras Slack channel](https://keras-slack-autojoin.herokuapp.com/) and ask there instead of filing a GitHub issue.\r\n\r\nThank you!\r\n\r\n- [X] Check that you are up-to-date with the master branch of Keras. You can update with:\r\npip install git+git://github.com/fchollet/keras.git --upgrade --no-deps\r\n\r\n- [X] If running on TensorFlow, check that you are up-to-date with the latest version. The installation instructions can be found [here](https://www.tensorflow.org/get_started/os_setup).\r\n\r\n- [ ] If running on Theano, check that you are up-to-date with the master branch of Theano. You can update with:\r\npip install git+git://github.com/Theano/Theano.git --upgrade --no-deps\r\n\r\n- [ ] Provide a link to a GitHub Gist of a Python script that can reproduce your issue (or just copy the script here if it is short).\r\n'],
                ['We need to make the classic benchmarks API as coherent and homogeneous as possible. For example, at the moment only some of those offer the possibility to specify the `data_root`. '],
                ['The documentation for class `ElasticNetCV()` reads:\r\n\r\n    y : array-like, shape (n_samples,) or (n_samples, n_targets)\r\n\r\nHowever, when I try to pass a 2D array I get the error:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-33-597417f0a72a> in <module>()\r\n      2 \r\n      3 enet = ElasticNetCV()\r\n----> 4 enet.fit(X_train, y_train)\r\n\r\n/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/coordinate_descent.py in fit(self, X, y)\r\n   1091             if y.ndim > 1 and y.shape[1] > 1:\r\n   1092                 raise ValueError("For multi-task outputs, use "\r\n-> 1093                                  "MultiTask%sCV" % (model_str))\r\n   1094             y = column_or_1d(y, warn=True)\r\n   1095         else:\r\n\r\nValueError: For multi-task outputs, use MultiTaskElasticNetCV\r\n```\r\n\r\n'],
                ['I just noticed that fsl comes installed with a hell lot of interesting atlases: HarvardOxford, Juelich, JHU, MNI, etc.\n\nShould we have the possibility to fetching this (at least locally when present) ? For example, I find the Juelich atlas really interesting.\n\n![inversecovariance](https://cloud.githubusercontent.com/assets/634068/16281427/b09127d4-38c4-11e6-9545-0dade0a10e0c.png)\n'],
                ["The ray dashboard is nice for the browser, however I find it kind of a pain to deal with opening the browser every time I want to view the progress, also it doesn't work very well without ssh tunneling.\r\n\r\nI am a huge fan of `nvidia-smi` and `top` for monitoring a single machine, works really well with `tmux`. I think theres a lot of potential for ray to have something similar for cluster resource viewing, especially with their agent logical views and such. \r\n\r\n![Screenshot from 2020-05-14 16-55-12](https://user-images.githubusercontent.com/26421036/81997122-b7be6d00-9603-11ea-85bc-e08496f32178.png)\r\n\r\nBasically just take all of the information being provided to the ray dashboard web page, and allow access to the headnode through the cli, something like `raysources`, and live monitoring with `watch raysources`, much like `watch nvidia-smi`.\r\n\r\n"],
                ['## Problem Description\r\nProcgen Environments (https://github.com/openai/procgen) are new environments to test out the generalization ability of agents. It would be nice to include some of the games into the Open RL Benchmark (http://benchmark.cleanrl.dev/)\r\n\r\nThis is a good first issue for contributors. I think contributors can simply modify the network model slightly (https://github.com/vwxyzjn/cleanrl/blob/db007392b20daea079633118c89cec2a243d1117/cleanrl/ppo_atari_visual.py#L514) to handle the Procgen Environments.\r\n\r\n'],
                ['Add this guideline to Optuna tutorial (as a part of distributed optimization section?).\r\n'],
                ['### Willingness to contribute\r\nThe MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?\r\n\r\n- [ ] Yes. I can contribute a fix for this bug independently.\r\n- [x] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.\r\n- [ ] No. I cannot contribute a bug fix at this time.\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 11.1\r\n- **MLflow installed from (source or binary)**: \r\n- **MLflow version (run ``mlflow --version``)**: 1.13.1\r\n- **Python version**: 3.8.5\r\n- **npm version, if running the dev UI**:\r\n- **Exact command to reproduce**: \r\n\r\n### Describe the problem\r\nPandas supports `ExtensionDtypes` for extending types from numpy. These types allow additional functionality (like `NA` support for bools or ints). However, calling `infer_signature` on a dataframe with these types fails because the columns are not of type `numpy.ndarray`.\r\n\r\n### Code to reproduce issue\r\n```\r\nimport pandas as pd\r\nfrom mlflow.models import infer_signature\r\n\r\ndf = pd.DataFrame(\r\n    {\r\n        "ints": [1, 2, 3],\r\n        "bools": [True, False, True],\r\n        "strings": ["a", "b", "c"]\r\n    }\r\n)\r\n\r\n# doing any of the following will cause infer_signature to fail\r\ndf["ints"] = df["ints"].astype("Int64")\r\ninfer_signature(df)\r\n\r\ndf["bools"] = df["bools"].astype("boolean")\r\ninfer_signature(df)\r\n\r\ndf["strings"] = df["strings"].astype("string")\r\ninfer_signature(df)\r\n```\r\n\r\n### Other info / logs\r\n```\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-122-64641ea9310a> in <module>\r\n      1 df["strings"] = df["strings"].astype("string")\r\n----> 2 infer_signature(df)\r\n\r\n~/opt/anaconda3/envs/fts/lib/python3.8/site-packages/mlflow/models/signature.py in infer_signature(model_input, model_output)\r\n    121     :return: ModelSignature\r\n    122     """\r\n--> 123     inputs = _infer_schema(model_input)\r\n    124     outputs = _infer_schema(model_output) if model_output is not None else None\r\n    125     return ModelSignature(inputs, outputs)\r\n\r\n~/opt/anaconda3/envs/fts/lib/python3.8/site-packages/mlflow/types/utils.py in _infer_schema(data)\r\n     62     elif isinstance(data, pd.DataFrame):\r\n     63         schema = Schema(\r\n---> 64             [ColSpec(type=_infer_numpy_array(data[col].values), name=col) for col in data.columns]\r\n     65         )\r\n     66     elif isinstance(data, np.ndarray):\r\n\r\n~/opt/anaconda3/envs/fts/lib/python3.8/site-packages/mlflow/types/utils.py in <listcomp>(.0)\r\n     62     elif isinstance(data, pd.DataFrame):\r\n     63         schema = Schema(\r\n---> 64             [ColSpec(type=_infer_numpy_array(data[col].values), name=col) for col in data.columns]\r\n     65         )\r\n     66     elif isinstance(data, np.ndarray):\r\n\r\n~/opt/anaconda3/envs/fts/lib/python3.8/site-packages/mlflow/types/utils.py in _infer_numpy_array(col)\r\n    138 def _infer_numpy_array(col: np.ndarray) -> DataType:\r\n    139     if not isinstance(col, np.ndarray):\r\n--> 140         raise TypeError("Expected numpy.ndarray, got \'{}\'.".format(type(col)))\r\n    141     if len(col.shape) > 1:\r\n    142         raise MlflowException("Expected 1d array, got array with shape {}".format(col.shape))\r\n\r\nTypeError: Expected numpy.ndarray, got \'<class \'pandas.core.arrays.string_.StringArray\'>\'\r\n```\r\n\r\n\r\n### What component(s), interfaces, languages, and integrations does this bug affect?\r\nComponents \r\n- [ ] `area/artifacts`: Artifact stores and artifact logging\r\n- [ ] `area/build`: Build and test infrastructure for MLflow\r\n- [ ] `area/docs`: MLflow documentation pages\r\n- [ ] `area/examples`: Example code\r\n- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry\r\n- [x] `area/models`: MLmodel format, model serialization/deserialization, flavors\r\n- [ ] `area/projects`: MLproject format, project running backends\r\n- [ ] `area/scoring`: Local serving, model deployment tools, spark UDFs\r\n- [ ] `area/server-infra`: MLflow server, JavaScript dev server\r\n- [ ] `area/tracking`: Tracking Service, tracking client APIs, autologging\r\n\r\nInterface \r\n- [ ] `area/uiux`: Front-end, user experience, JavaScript, plotting\r\n- [ ] `area/docker`: Docker use across MLflow\'s components, such as MLflow Projects and MLflow Models\r\n- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry\r\n- [ ] `area/windows`: Windows support\r\n\r\nLanguage \r\n- [ ] `language/r`: R APIs and clients\r\n- [ ] `language/java`: Java APIs and clients\r\n- [ ] `language/new`: Proposals for new client languages\r\n\r\nIntegrations\r\n- [ ] `integrations/azure`: Azure and Azure ML integrations\r\n- [ ] `integrations/sagemaker`: SageMaker integrations\r\n- [ ] `integrations/databricks`: Databricks integrations\r\n'],
                ['The current paga plot output a n_row =1 plot, which is not very user-friendly. It would be nice to have an option to control n_col as other plot functions in scanpy do. Thanks!'],
                ['Any suggestions on how to make `vaex` support nc-4 files, which are themselves backed by hdf5?\r\n\r\nWhen attempting to read a netCDF-4 file with a given variable in (x,y,z,t) coordinates this is what I get:\r\n\r\n`ValueError: array is of length 360, while the length of the DataFrame is 2928`\r\n\r\nThis netCDF-4 file contains 360 latitude values, and 2928 time points, as evidenced by `ncdump -h`:\r\n\r\n```\r\nnetcdf GSWP3.BC.Rainf.3hrMap.1940 {\r\ndimensions:\r\n\ttime = UNLIMITED ; // (2928 currently)\r\n\tlat = 360 ;\r\n\tlon = 720 ;\r\nvariables:\r\n\tdouble time(time) ;\r\n\t\ttime:long_name = "Time" ;\r\n\t\ttime:standard_name = "time" ;\r\n\t\ttime:calendar = "proleptic_gregorian" ;\r\n\t\ttime:units = "hours since 1871-01-01 00:00:00" ;\r\n\tfloat lat(lat) ;\r\n\t\tlat:long_name = "Latitude" ;\r\n\t\tlat:standard_name = "latitude" ;\r\n\t\tlat:axis = "Y" ;\r\n\t\tlat:units = "degrees_north" ;\r\n\tfloat lon(lon) ;\r\n\t\tlon:long_name = "Longitude" ;\r\n\t\tlon:standard_name = "longitude" ;\r\n\t\tlon:axis = "X" ;\r\n\t\tlon:units = "degrees_east" ;\r\n\tfloat Rainf(time, lat, lon) ;\r\n\t\tRainf:_fillvalue = 1.e+20 ;\r\n\t\tRainf:long_name = "Rainfall rate" ;\r\n\t\tRainf:standard_name = "rainfall_flux" ;\r\n\t\tRainf:alma_name = "Rainf" ;\r\n\t\tRainf:amip_name = "prra" ;\r\n\t\tRainf:units = "kg m-2 s-1" ;\r\n// global attributes:\r\n\t\t:title = "Global Soil Wetness Project 3 <http://hydro.iis.u-tokyo.ac.jp/GSWP3> EXP1 forcing data" ;\r\n\t\t:id = "GSWP3.BC.Rainf.3hrMap.1940" ;\r\n\t\t:creator = "Hyungjun Kim <hjkim@iis.u-tokyo.ac.jp>" ;\r\n\t\t:institution = "Institute of Industrial Science, The University of Tokyo" ;\r\n\t\t:contributors = "Satoshi Watanabe, Eun-Chul Chang, Nobuyuki Utsumi, Kei Yoshimura, Gilbert Compo, Hirabayashi Yukiko, James Famiglietti, and Taikan Oki" ;\r\n\t\t:conventions = "ALMA-3, CF-1.6, AMIP" ;\r\n\t\t:history = "| 0.5b | 2014-06-22 | first beta release\\n| 0.6b | 2014-07-18 | remove negative values from Qair\\n| 0.7b | 2014-10-15 | add netCDF description\\n|                   | beta version release\\n| 0.8b | 2017-05-12 | correct wind using CRU-CL2.0\\n| 0.9b | 2017-05-13 | correct bias of reference Prcp (GPCC v7) in early 20th Century\\n|                   | reproduce Rainf/Snowf corresponding to updated wind speed\\n| 1.0  | 2017-06-01 | version 1 official release\\n| 1.05 | 2018-02-17 | timespan extended (1901-2014)\\n|                   | fill wind values over ocean pixels with downscaled reanalysis\\n| 1.06 | 2018-07-06 | change variable naming convention: amip_name [wss] -> [sfcWind]" ;\r\n}\r\n```'],
                ["Python version 2.7.12\r\ngensim version 0.13.2\r\n\r\nI'm serializing my corpus into Blei LDA-C format using `corpora.BleiCorpus.serialize(filename, corpus)` which is then later used in a dynamic topic model, and not in python. (I know I can use the DTMModel wrapper, unrelated.)\r\n\r\nIf I need to come back and load the corpus back into Python I tried `corpora.BleiCorpus.load(filename)`, I get an unpickling error:\r\n\r\n     ---------------------------------------------------------------------------\r\n     UnpicklingError                           Traceback (most recent call last)\r\n    <ipython-input-28-0dd15393a941> in <module>()\r\n    ----> 1 test = corpora.BleiCorpus.load('corpus-mult.dat')\r\n\r\n    /Applications/anaconda/envs/py27/lib/python2.7/site-packages/gensim/utils.pyc in load(cls, fname, mmap)\r\n        246         compress, subname = SaveLoad._adapt_by_suffix(fname)\r\n        247 \r\n    --> 248         obj = unpickle(fname)\r\n        249         obj._load_specials(fname, mmap, compress, subname)\r\n        250         return obj\r\n\r\n    /Applications/anaconda/envs/py27/lib/python2.7/site-packages/gensim/utils.pyc in unpickle(fname)\r\n        909     with smart_open(fname) as f:\r\n        910         # Because of loading from S3 load can't be used (missing readline in smart_open)\r\n    --> 911         return _pickle.loads(f.read())\r\n        912 \r\n        913 \r\n\r\n    UnpicklingError: invalid load key, '7'.\r\n\r\nThe only other argument to `load()` is `mmap` but I don't believe the arrays were stored separately and using `mmap='r'` doesn't help anyway."],
                ['Orchest can be configured using the `config.json` file (see [the docs](https://orchest.readthedocs.io/en/latest/user_guide/other.html#global-configurations)). Currently, default values for these configuration options are a bit scattered across the code base. \r\n\r\nThe default values should instead be set in the internal `lib`.'],
                ["Hello there,\r\n\r\nI would like to use [plotting.plot_roi](https://nilearn.github.io/modules/generated/nilearn.plotting.plot_roi.html#nilearn.plotting.plot_roi) function to plot ROIs with colors defined in [FreeSurferColorLUT](https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/AnatomicalROI/FreeSurferColorLUT).\r\nI believe I need to play with `cmap` argument for the above purpose. The task would be to covert RGBA from the LUT to a value that `cmap` can accept.\r\n\r\nI have been looking at [matplotlib.colors.ListedColormap](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.colors.ListedColormap.html#matplotlib.colors.ListedColormap.html) to understand how that is possible but haven't been able to figure out yet. Can anyone please help?"],
                ["## Motivation\r\n\r\nFrom following resources, the search space of `examples/xgboost_simple.py` seems not to be practical.\r\n\r\n* https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\r\n* https://www.youtube.com/watch?v=VC8Jc9_lNoY\r\n* https://www.amazon.co.jp/dp/B07YTDBC3Z/\r\n\r\n## Description\r\n\r\nImprove the search space of `examples/xgboost_simple.py`.\r\n\r\n## Additional context (optional)\r\n\r\n<!-- Please add any other context or screenshots about the feature request here. -->\r\n\r\nI once opened #1574, but I'm not familiar with XGBoost very much.\r\nSo I closed my pull request and opened this issue.\r\n\r\nI think this ticket is good for first-time contributor."],
                ["**Motivation: Why do you think this is important?**\r\nFlytekit should support Vaex as a pandas alternative for FlyteSchema object.\r\nhttps://github.com/vaexio/vaex\r\n\r\nVaex has great performance on a single machine, which is usually needed for most datasets. Spark & dask are overkill with lots of complexity for datasets of sizes in few gigabytes. Addition of Vaex and support for automatic serialization and deserialization between consecutive tasks using Arrow/HDF5 would allow great Pandas, Spark and Vaex inter-operability.\r\n\r\n**Goal: What should the final outcome look like, ideally?**\r\nUsers should be able to retrieve Vaex Dataframes from a FlyteSchema\r\n```python\r\ndef foo(f: FlyteSchema):\r\n    df = f.open(type=vaex.DataFrame)\r\n    ...\r\n```\r\n\r\nAlso support for Vaex Dataframe as a type\r\n```python\r\ndef foo(f: vaex.DataFrame) -> vaex.DataFrame:\r\n   pass\r\n```\r\n\r\nThe plugin should mostly look like the default Pandas DataFrame Transformer and Reader that ships with Flytekit\r\nhttps://github.com/flyteorg/flytekit/blob/master/flytekit/types/schema/types_pandas.py#L88-L144\r\n\r\nOr like the Spark Plugin support for Spark DataFrames like\r\nhttps://github.com/flyteorg/flytekit/blob/master/plugins/spark/flytekitplugins/spark/schema.py#L13-L81\r\n\r\n**Describe alternatives you've considered**\r\nNA\r\n\r\n**Flyte component**\r\n- [ ] Overall\r\n- [ ] Flyte Setup and Installation scripts\r\n- [ ] Flyte Documentation\r\n- [ ] Flyte communication (slack/email etc)\r\n- [ ] FlytePropeller\r\n- [ ] FlyteIDL (Flyte specification language)\r\n- [x] Flytekit (Python SDK)\r\n- [ ] FlyteAdmin (Control Plane service)\r\n- [ ] FlytePlugins\r\n- [ ] DataCatalog \r\n- [ ] FlyteStdlib (common libraries)\r\n- [ ] FlyteConsole (UI)\r\n- [ ] Other\r\n\r\n\r\n"],
                ['Add (Diaz-Rodriguez, 2018) metrics (A, MS, SSS, CE, CLscore, CLstability)'],
                ['No description provided.'],
                ['Hi, thanks for the great code!\r\n\r\nI wonder do you have plans to support resuming from checkpoints for classification? As we all know, in terms of training ImageNet, the training process is really long and it can be interrupted somehow, but I haven\'t notice any code related to "resume" in `scripts/classification/train_imagenet.py`.\r\n\r\nMaybe @hetong007 ? Thanks in advance.'],
                ["Currently, if `trial.report()` method is called multiple times with the same step in a trial, only the first reported value will be recorded into the storage and the others will be silently ignored.\r\nReporting multiple values with the same step is an unintended usage of the method, and it could cause bugs that are hard to notice (see #847 as an example of such bug).\r\nTherefore, it seems better to add a check to detect the duplicate reports, and if it's detected, we should emit a warning message.\r\n\r\nAs an implementation note, this modification could be done without any additional DB costs (see https://github.com/optuna/optuna/pull/847#issuecomment-576512000 for the detail)."],
                ["We've made great strides to add type hints to our code. However, we're not done yet. Running [`mypy`](http://mypy-lang.org/) still raises errors. It would be great to spend some time and finish tidying up our code to satisfy `mypy`. I can then `mypy` to the tests workflow in the CI."],
                ['- [ ] MEPS dataset\r\n- [ ] differential fairness metrics\r\n- [ ] rich subgroup fairness'],
                ['## Description\r\nTVM support has been added in https://github.com/dmlc/gluon-nlp/pull/1390. Also, we updated our benchmarking utility to support profiling the inference speed of TVM: https://github.com/dmlc/gluon-nlp/tree/master/scripts/benchmarks. We can further improve our document.\r\n\r\n- [ ] Attach the benchmark numbers. (Good for beginners)\r\n- [ ] Add a tutorial about how to convert GluonNLP models to TVM and do inference. (Good for beginners)\r\n- [ ] Investigate the numerical issues triggered when converting ALBERT to TVM. Currently, the test may still sometimes fail even if `atol=1E-1`, `rtol=1E-3`.\r\n\r\n@dmlc/gluon-nlp-committers \r\n'],
                ['Per https://github.com/tensorflow/tensorflow/issues/28601 it has been recommended that we fork and expose `keras.layer_test` for this project and others to utilize.\r\n\r\nAny thoughts where we should put test utilities? I think for this one it makes sense somewhere under tfa.layers, but we might want the central tfa.utils location for all test utilities?'],
                ['Running CircleCI, we get a TON of deprecation warnings. This will be a problem in the future when the bill is suddenly due (and we may not forsee the deadline, since there are so many), and right now it makes the already verbose output of CI systems and makes it worse.\r\n\r\nWe should consider slowly attending to the deprecations as we go about fixing other stuff.'],
                ['No description provided.'],
                ["## 🚀 Feature\r\n<!-- A clear and concise description of the feature proposal -->\r\n\r\n### Motivation\r\n\r\nThe goal is to create single point of truth about stages for the trainer, so we don't get typo errors.\r\n\r\n<!-- Please outline the motivation for the proposal. Is your feature request related to a problem? e.g., I'm always frustrated when [...]. If this is related to another GitHub issue, please link here too -->\r\n\r\n### Pitch\r\n\r\n<!-- A clear and concise description of what you want to happen. -->\r\n\r\n### Alternatives\r\n\r\n<!-- A clear and concise description of any alternative solutions or features you've considered, if any. -->\r\n\r\n### Additional context\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n"],
                ['No description provided.'],
                ['# Feature request: Support TFP\'s (L-)BFGS optimiser\r\n\r\nTensorFlow Probability (TFP) has a native TensorFlow implementation of the (L-)BFGS optimiser. Currently, GPflow doesn\'t use this and relies on scipy\'s implementation. The problem with this, however, is that in each step of the optimisation we have to leave "graph" mode and pass in NumPy values directly to SciPy - possibly introducing a computational inefficiency.   \r\n\r\n## Proposal\r\n\r\nIt would be nice to make TFP\'s optimisers available in GPflow. Here\'s a quick and dirty stab at it:\r\n```python\r\n# Copyright © 2019 Pi-Yueh Chuang <pychuang@gwu.edu>\r\n# Copyright © 2017-2020 The GPflow Contributors. All Rights Reserved.\r\n# Copyright © 2020 Vincent Dutordoir <vincent@secondmind.ai>\r\n#\r\n# Distributed under terms of the MIT license.\r\n\r\n\r\nfrom typing import Sequence, Union, List\r\n\r\nimport gpflow\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport tensorflow_probability as tfp\r\nfrom matplotlib import pyplot as plt\r\n\r\n\r\ndef pack_tensors(tensors: Sequence[Union[tf.Tensor, tf.Variable]]) -> tf.Tensor:\r\n    flats = [tf.reshape(tensor, (-1,)) for tensor in tensors]\r\n    tensors_vector = tf.concat(flats, axis=0)\r\n    return tensors_vector\r\n\r\n\r\ndef unpack_tensors(\r\n    to_tensors: Sequence[Union[tf.Tensor, tf.Variable]], from_vector: tf.Tensor\r\n) -> List[tf.Tensor]:\r\n    s = 0\r\n    values = []\r\n    for target_tensor in to_tensors:\r\n        shape = tf.shape(target_tensor)\r\n        dtype = target_tensor.dtype\r\n        tensor_size = tf.reduce_prod(shape)\r\n        tensor_vector = from_vector[s : s + tensor_size]\r\n        tensor = tf.reshape(tf.cast(tensor_vector, dtype), shape)\r\n        values.append(tensor)\r\n        s += tensor_size\r\n    return values\r\n\r\n\r\ndef assign_tensors(to_tensors: Sequence[tf.Variable], values: Sequence[tf.Tensor]) -> None:\r\n    if len(to_tensors) != len(values):\r\n        raise ValueError("to_tensors and values should have same length")\r\n    for target, value in zip(to_tensors, values):\r\n        target.assign(value)\r\n\r\n\r\ndef create_value_and_gradient_function(loss_closure, trainable_variables, verbose=1):\r\n    """A factory to create a function required by tfp.optimizer.lbfgs_minimize.\r\n    Args:\r\n        loss_closure:\r\n        trainable_variables:\r\n    Returns:\r\n        A function that has a signature of:\r\n            loss_value, gradients = f(model_parameters).\r\n    """\r\n    i = tf.Variable(0)\r\n\r\n    def assign_param_values_to_variables(x):\r\n        values = unpack_tensors(trainable_variables, x)\r\n        assign_tensors(trainable_variables, values)\r\n\r\n    @tf.function\r\n    def f_value_and_gradients(x):\r\n        """A function that can be used by tfp.optimizer.lbfgs_minimize"""\r\n        # update params\r\n        assign_param_values_to_variables(x)\r\n        # compute loss value and gradients w.r.t. trainable variables\r\n        with tf.GradientTape(watch_accessed_variables=False) as tape:\r\n            tape.watch(trainable_variables)\r\n            loss_value = loss_closure()\r\n        grads = tape.gradient(loss_value, trainable_variables)\r\n\r\n        i.assign_add(1)\r\n        if verbose > 0:\r\n            tf.print("Iter:", i, "loss:", loss_value)\r\n\r\n        # return loss and flattened gradients\r\n        return loss_value, pack_tensors(grads)\r\n\r\n    return f_value_and_gradients, assign_param_values_to_variables\r\n\r\n\r\ndef plot_helper(inputs, outputs, title):\r\n    """Plot helper"""\r\n    plt.figure()\r\n    plt.tricontourf(inputs[:, 0], inputs[:, 1], outputs.flatten(), 100)\r\n    plt.xlabel("x")\r\n    plt.ylabel("y")\r\n    plt.title(title)\r\n    plt.colorbar()\r\n\r\n\r\nif __name__ == "__main__":\r\n    # use float64 by default\r\n    tf.keras.backend.set_floatx("float64")\r\n\r\n    # prepare training data\r\n    x_1d = np.linspace(-1.0, 1.0, 11)\r\n    x1, x2 = np.meshgrid(x_1d, x_1d)\r\n    inps = np.stack((x1.flatten(), x2.flatten()), 1)\r\n    outs = np.reshape(inps[:, 0] ** 2 + inps[:, 1] ** 2, (x_1d.size ** 2, 1))\r\n    data = (inps, outs)\r\n\r\n    model = gpflow.models.GPR(data, gpflow.kernels.RBF())\r\n    loss_closure = model.training_loss_closure()\r\n\r\n    func, assign = create_value_and_gradient_function(\r\n        loss_closure=loss_closure, trainable_variables=model.trainable_variables,\r\n    )\r\n    print("Before training", loss_closure())\r\n\r\n    # # convert initial model parameters to a 1D tf.Tensor\r\n    init_params = pack_tensors(model.trainable_variables)\r\n\r\n    # # train the model with L-BFGS solver\r\n    results = tfp.optimizer.lbfgs_minimize(\r\n        value_and_gradients_function=func, initial_position=init_params, max_iterations=5\r\n    )\r\n\r\n    # after training, the final optimized parameters are still in results.position\r\n    # so we have to manually put them back to the model\r\n    assign(results.position)\r\n    print("After training", loss_closure())\r\n\r\n    # # do some prediction\r\n    pred_outs = model.predict_f(inps)[0].numpy()\r\n    err = np.abs(pred_outs - outs)\r\n    print("L2-error norm: {}".format(np.linalg.norm(err) / np.sqrt(11)))\r\n\r\n    # plot figures\r\n    plot_helper(inps, outs, "Exact solution")\r\n    plot_helper(inps, pred_outs, "Predicted solution")\r\n    plot_helper(inps, err, "Absolute error")\r\n    plt.show()\r\n```'],
                ['## Current Observation\r\n\r\nChallenge hosts can set the challenge phase start and end date to anything irrespective of the challenge start and end date.\r\n\r\n## Deliverables\r\n\r\nAdd the following checks in proper places in the codebase (i.e some/all of these things would go in the ChallengePhase `save()` method)\r\n- [ ] Challenge phase start datetime >= Challenge start datetime\r\n- [ ] Challenge phase start datetime < Challenge end datetime\r\n- [ ] Challenge phase end datetime > Challenge start datetime\r\n- [ ] Challenge phase end datetime <= Challenge end datetime\r\n- [ ] Challenge phase start datetime < Challenge phase end datetime\r\n\r\n## Extended Goal \r\n\r\n- [ ] Add check if Challenge start datetime < Challenge end datetime'],
                ["It would be nice to have a function which returns a list of the xyz coordinates of the first 'n' local maxima ? (or just the the n maximal voxels, without being necessarily local maxima)\r\n\r\n "],
                ['It takes a lot of time and energy to create beautiful charts for including in research papers.\r\nAim should enable way for researchers to customize and export any chart image that is relevant for their research paper.\r\n\r\nPotential flow:\r\n- Click on any plot to export\r\n- A modal/popup appears with options to edit legends, size and other info on the plot\r\n- Export plot as svg or png'],
                ['Warning from GitHub Actions:\r\n\r\n> The `add-path` command is deprecated and will be disabled soon. Please upgrade to using Environment Files. For more information see: https://github.blog/changelog/2020-10-01-github-actions-deprecating-set-env-and-add-path-commands/\r\n\r\nWe need to upgrade to use environment files for GitHub Actions going forward.'],
                ['# Feature request\r\n\r\nProvide additional interfaces/methods that may be needed when working with non-Gaussian likelihoods.\r\n\r\n## Motivation\r\n\r\n**Why does this matter?**\r\nWhen the observation ("noise") model is not Gaussian, we commonly want to know more than just mean and variance. Let\'s make that easier!\r\n\r\nCurrently, the only way to predict in the observation space (y) is `model.predict_y()`, which in turn calls `likelihood.predict_mean_and_var()` and returns the mean and variance. While we can evaluate this for (almost) all non-Gaussian likelihoods, this may not always be relevant. (E.g., for Bernoulli and Poisson likelihoods, the variance is deterministically related to the mean.) It would be great to improve the capabilities GPflow offers for non-Gaussian likelihoods.\r\n\r\nFor example, just as we provide predict_f_samples, we could also provide predict_y_samples -- this would then allow computation of empirical quantiles, expectations, etc. This would require adding a Likelihood.sample_y() method for each likelihood that defines how to draw a sample of y given f.\r\n\r\nOne way of implementing this:\r\n* Add `conditional_sample(self, F, sample_shape)` method to the `Likelihood` interface, which draws samples from p(y | F). For consistency with tensorflow_probability, the sample_shape should be preprended to the shape of the distribution.\r\n* Add `predict_y_samples(self, Xnew, sample_shape)` method to the `GPModel` interface, which combines `predict_f_samples` with `likelihood.conditional_sample`.\r\n\r\nOpen questions:\r\n* What quantities do we actually want to evaluate? Are quantiles the way to go - could we implement that in closed form (not going via predict_y_samples)? What else would be helpful?\r\n* How to handle SwitchedLikelihood - how would we specify which likelihood to sample from - this would require passing the "which-likelihood" column Ynew as well as Xnew... or simply skip this?\r\n* Is `observation_dim` too unspecific for sampling observations?'],
                ['First of all, many thanks for the great tutorials for object detection using pre-trained models. The code is so simple and easier to follow.\r\n\r\nThe problem is that custom object detection (with a small dataset) and transfer learning tutorials are complicated for beginners. I saw a tutorial somewhere that shows custom object detection using just 5 lines of code. Can you write a simple tutorial for us?\r\n\r\nThis looks very complicated. \r\nhttps://gluon-cv.mxnet.io/build/examples_classification/transfer_learning_minc.html\r\nDo we really need to learn all these details while you have such a great high level API?\r\n\r\nI am sorry if this is not the right place to post this question but I need your help on this.\r\n\r\nThanks again.\r\n'],
                ["How can i implement callback parameter in fit moder Autoencoder ?\r\nThere is not parameter.\r\n\r\nfrom keras.callbacks.callbacks import EarlyStopping\r\ncb_earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, \r\n                                            mode='auto', baseline=None, restore_best_weights=False)\r\npyod_model.fit(scaler, callbacks=[cb_earlystop])\r\n\r\nTypeError: fit() got an unexpected keyword argument 'callbacks'\r\n\r\nCan you implement this parameter? Its very usefull for monitor, early stop and another cases.\r\n"],
                ["## Objective\r\n\r\nPython 3.6 and above supports [type hints](https://www.python.org/dev/peps/pep-0484/) and optional statically typing of Python code. Since its introduction is has seen a lot of adoption in many Python projects in particular in larger code bases. Type hints are completely optional and are stripped by the Python parser before runtime.\r\n\r\nI am not the only one @plumerai anymore who likes type hints for Python and we only support Python 3.6+ already so I'd like to discuss if we should introduce type hints to the `larq` code base. I have never used typings in a big project, but below is a list of some pros and cons I can think of on top of my head.\r\n\r\n## Pros\r\n- Makes it easy to reason about the code due to the self documenting nature of statically typed functions\r\n- Helps with code review\r\n- Can catch subtle bugs of in places of insufficient code coverage\r\n- Has good integrations for editors that help with autocomplete and linting\r\n\r\n## Cons\r\n- TensorFlow doesn't use type hints so I don't know how well type stubs are maintained\r\n- Needs additional setup on CI and to maintain type stubs\r\n- Might be confusing for novice Python users since it adds new syntax to the `larq` code base\r\n\r\n## Tooling\r\n- [MyPy](http://www.mypy-lang.org/) (the default)\r\n- [Typeshed](https://github.com/python/typeshed)\r\n- [Pyre](https://pyre-check.org/)\r\n- [Pytype](https://google.github.io/pytype/)"],
                ['No description provided.'],
                ['Issue #3644 describes the reasons why this warning was created. However, I get this warning even with as little as 17 actors:\r\n\r\n![2020-07-09_15-13](https://user-images.githubusercontent.com/5415776/87075630-0b5dc900-c1f7-11ea-8ca8-9f75cee0a460.png)\r\n\r\nAccording to `ulimit -n` I can safely run many more procs.\r\n\r\nPotential solutions:\r\n- Allow to specify number of acceptable actors before warning\r\n- By default, warn once instead of spamming this warning dozens of times, or warn only once per second.'],
                ['As of the PyTorch 1.6 [release](https://pypi.org/project/torch/1.6.0/) on July 28th, 2020, there is a native type for tensors of complex numbers (see: https://pytorch.org/docs/stable/complex_numbers.html)\r\n\r\nFrom @mberr: Referencing the 1.7.1 release tracker here, in case they mention something about it: https://github.com/pytorch/pytorch/issues/47622\r\n\r\nIt would be interesting to test updated implementations of models using complex tensors such as RotatE and ComplEx to see if we can make them more elegant using this new trick. #292 is a good solution, but still not native. #134 presents a solution where the tensors themselves inside the Embedding are assigned the complex dtype like in:\r\n\r\n```python\r\n...\r\n# initialize weight outside of torch.nn.Embedding to sneak in the dtype definitiion\r\n_weight = torch.empty((num_embeddings, embedding_dim), dtype=dtype)\r\n\r\nself._embeddings = torch.nn.Embedding(\r\n    num_embeddings=num_embeddings,\r\n    embedding_dim=embedding_dim,\r\n    _weight=_weight,\r\n)\r\n...\r\n```\r\n\r\nThen, the math in ComplEx can be updated like in:\r\n\r\n```python\r\n# old\r\n(h_re, h_im), (r_re, r_im), (t_re, t_im) = [split_complex(x=x) for x in (h, r, t)]\r\n\r\n# new\r\nh_re, h_im = h.real, h.imag\r\nr_re, r_im = r.real, r.imag\r\nt_re, t_im = t.real, t.imag\r\n````\r\n\r\nHowever, this update is blocked by a major issue - the `torch.nn.functional.embedding` function does not currently support automatic differentiation on complex tensors.\r\n\r\n```python-traceback\r\nTraceback (most recent call last):\r\n  File "/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/unittest/case.py", line 60, in testPartExecutor\r\n    yield\r\n  File "/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/unittest/case.py", line 676, in run\r\n    self._callTestMethod(testMethod)\r\n  File "/usr/local/opt/python@3.8/Frameworks/Python.framework/Versions/3.8/lib/python3.8/unittest/case.py", line 633, in _callTestMethod\r\n    method()\r\n  File "/Users/cthoyt/dev/pykeen/tests/test_models.py", line 439, in test_score_r_with_score_hrt_equality\r\n    raise e\r\n  File "/Users/cthoyt/dev/pykeen/tests/test_models.py", line 431, in test_score_r_with_score_hrt_equality\r\n    scores_r = self.model.score_r(batch)\r\n  File "/Users/cthoyt/dev/pykeen/src/pykeen/models/base.py", line 993, in score_r\r\n    expanded_scores = self.score_hrt(hrt_batch=hrt_batch)\r\n  File "/Users/cthoyt/dev/pykeen/src/pykeen/models/unimodal/complex.py", line 151, in score_hrt\r\n    h = self.entity_embeddings(indices=hrt_batch[:, 0])\r\n  File "/Users/cthoyt/.virtualenvs/pykeen/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File "/Users/cthoyt/dev/pykeen/src/pykeen/nn/emb.py", line 177, in forward\r\n    x = self._embeddings(indices)\r\n  File "/Users/cthoyt/.virtualenvs/pykeen/lib/python3.8/site-packages/torch/nn/modules/module.py", line 727, in _call_impl\r\n    result = self.forward(*input, **kwargs)\r\n  File "/Users/cthoyt/.virtualenvs/pykeen/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 124, in forward\r\n    return F.embedding(\r\n  File "/Users/cthoyt/.virtualenvs/pykeen/lib/python3.8/site-packages/torch/nn/functional.py", line 1852, in embedding\r\n    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\r\nRuntimeError: embedding does not support automatic differentiation for outputs with complex dtype.\r\n```\r\n'],
                ['The function `basic_paradigm` is defined in `nilearn._utils.data_gen.py`:\r\n\r\nhttps://github.com/nilearn/nilearn/blob/00d3873fb6cf23d09f8eba6d0d20e905f26d22dd/nilearn/_utils/data_gen.py#L505-L510\r\n\r\nBut, it is re-defined in other files (with a duration) for testing:\r\n\r\n- `nilearn/glm/tests/test_first_level.py`:\r\nhttps://github.com/nilearn/nilearn/blob/a36c0442fc8eebe401b310dd9799c0f071080e90/nilearn/glm/tests/test_first_level.py#L353-L360\r\n\r\n- `nilearn/glm/tests/test_paradigm.py`:\r\nhttps://github.com/nilearn/nilearn/blob/a36c0442fc8eebe401b310dd9799c0f071080e90/nilearn/glm/tests/test_paradigm.py#L16-L23\r\n\r\n- `nilearn/glm/tests/test_dmtx.py`:\r\nhttps://github.com/nilearn/nilearn/blob/a36c0442fc8eebe401b310dd9799c0f071080e90/nilearn/glm/tests/test_dmtx.py#L48-L55\r\n\r\nIt would be better to remove those and import `basic_paradigm` from `_utils.data_gen.py`.'],
                ['E.g. `dvc get https://github.com/user/proj /path/to/data` -> `dvc get https://github.com/user/proj path/to/data`. https://discordapp.com/channels/485586884165107732/485596304961962003/633731542539173889 So far, not seeing any reason against it.'],
                ["<!--Please include [tune], [rllib], [autoscaler] etc. in the issue title if relevant-->\r\n\r\n### Describe your feature request\r\nAt the moment, we can use redis for ray's health check, but if we ever remove our redis dependency, we will have no more centralized components and will need a more clever health check mechanism. "],
                ['We currently only support one argument in `couler.map()`, which is a list of values that can be called by the specified function.\r\n\r\nhttps://github.com/couler-proj/couler/blob/fedbcc42383eb3335d3fadddf818defcf74d70a4/couler/core/syntax/loop.py#L23-L32'],
                ['# Add multi-modal loss\r\n\r\nAs discussed in #249, adding the loss function as described in [CLIP](https://arxiv.org/pdf/2103.00020.pdf) would enable users to work with multi-modal datasets.\r\n\r\nThe pseudo-code (from the paper) is:\r\n![grafik](https://user-images.githubusercontent.com/65946090/112820828-4efaaa80-9086-11eb-95b4-4b8a9c3c0d6a.png)\r\n'],
                ['Contributors: @RNKuhns, @fkiraly, @mloning\r\n\r\nRelated issue: #718 \r\n\r\n### Estimators\r\n* new estimator scitype: DirectionalForecaster\r\n* reducer from Forecaster to DirectionalForecaster via time-series/tabular classification\r\n* reducer from Forecaster to DirectionalForecaster via output binning\r\n* override score in the reduced forecasters with the "right" binned losses!\r\n\r\n```python\r\ny_train, y_test = temporal_train_test_split(y)\r\nforecaster = ARIMA()\r\n\r\n# reduce forecaster to directional forecaster\r\ndforecaster = Reducer(forecaster, bins=[...])\r\ndforecaster.fit(y_train)\r\ny_pred = dforecaster.predict(fh)\r\n\r\n# score applies binning internally\r\ndforecaster.score(y_test, fh)\r\n```\r\n\r\n### Losses \r\n* directional accuracy metrics are new metrics scitype - compare actual with binned; `__call__` method without parameters, class hyperparams are binning\r\n\r\n```python\r\nmean_directional_loss(y_test, y_pred, bins=[...])\r\n```\r\n\r\nFranz opinion (because parameter arguments should not be part of the scitype-specific call signatures, but go to the constructor, according to "universal interface spec")\r\n```python\r\nscoring = MeanDirectionalLoss(bins=[...])\r\nscoring(y_test, y_pred)\r\n```\r\n\r\nwrapper for scikit-learn classification losses\r\n```python\r\nfrom sklearn import accuracy_loss\r\nmy_DL = make_directional_loss(accuracy_loss, bins=[...])\r\n```\r\n'],
                ['> Moving from https://github.com/iterative/dvc.org/issues/735#issuecomment-547727345\r\n\r\n```\r\n$ dvc version\r\nDVC version: 0.65.0\r\nPython version: 3.7.4\r\nPlatform: Darwin-19.0.0-x86_64-i386-64bit\r\nBinary: False\r\n```\r\n\r\nWhen you import a specific revision that doesn\'t change, for example a tag like:\r\n\r\n```console\r\n$ dvc import --rev cats-dogs-v1 \\\r\n             git@github.com:iterative/dataset-registry.git \\\r\n             use-cases/cats-dogs\r\nImporting \'use-cases/cats-dogs (git@github.com:iterative/dataset-registry.git)\' -> \'cats-dogs\'\r\nOutput \'cats-dogs\' didn\'t change. Skipping saving.                                                                                                           \r\nSaving information to \'cats-dogs.dvc\'.\r\n$ ls\r\ntotal 8\r\ndrwxr-xr-x  3 usr  staff    96B Oct 22 14:05 cats-dogs/\r\n-rw-r--r--  1 usr  staff   340B Oct 22 14:05 cats-dogs.dvc\r\n```\r\n\r\nAnd then you try to update, nothing changes because the `rev` never moves. However `dvc update` output doesn\'t really signal this, in fact it says "Saving information..." as if something happened:\r\n\r\n```console\r\n$ dvc update cats-dogs.dvc\r\nSaving information to \'cats-dogs.dvc\'.\r\n```\r\n\r\nAlthough this is correct update behavior (as explained in https://github.com/iterative/dvc.org/issues/735#issuecomment-545163407), maybe the output could be different when it detects a fixed rev field in the DVC-file, and this rev hasn\'t changed. It could give an INFO message to suggest the user may have to re-import instead of updating. Something like:\r\n\r\n```console\r\n$ dvc update cats-dogs.dvc\r\nNOTE: The \'cats-dogs.dvc\' import stage is fixed to revision \'cats-dogs-v1\'\r\nand this Git reference has not moved. You may want to re-import \'cats-dogs.dvc\'\r\nto un-fix it, instead of trying to update it.\r\n```\r\n'],
                ["## 🚀 Feature Request\r\n<!-- A clear and concise description of the feature proposal. -->\r\n\r\nLet's add samplers from [`facebookresearch/classifier-balancing`](https://github.com/facebookresearch/classifier-balancing) to [catalyst.data.sampler](https://github.com/catalyst-team/catalyst/blob/master/catalyst/data/sampler.py).\r\n\r\n### Motivation\r\n<!-- Please outline the motivation for the proposal. Is your feature request related to a problem? e.g., I'm always frustrated when [...]. If this is related to another GitHub issue, please link here too -->\r\n\r\nCatalyst already has a large variety of data samplers – let's compare them with the FB Research one and add them to our Data API.\r\n\r\n### Proposal\r\n<!-- \r\nA clear and concise description of what you want to happen.\r\nYou could use minimal examples - https://github.com/catalyst-team/catalyst#minimal-examples. \r\n-->\r\n\r\n- review the FB repo\r\n- make a refactoring - make the code cleaner for the implementations\r\n- make a PR for catalyst.data.sampler\r\n- add tests and docs for the community users\r\n\r\n### Alternatives\r\n<!-- A clear and concise description of any alternative solutions or features you've considered. -->\r\n\r\n\r\n### Additional context\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n\r\nThis is a great feature request for newcomers – only PyTorch knowledge required :)\r\n\r\n\r\n### Checklist\r\n- [x] feature proposal description.\r\n- [x] motivation.\r\n- [x] extra proposal context / proposal alternatives review.\r\n- [x] I know, that I could [join Catalyst slack (#__questions channel)](https://join.slack.com/t/catalyst-team-core/shared_invite/zt-d9miirnn-z86oKDzFMKlMG4fgFdZafw) for issue discussion.\r\n"],
                ['In runtime configurations, it would be helpful to import/export runtime configurations.\r\nIn addition, importing / exporting a list or selection of configurations would be a nice additional feature\r\n\r\n![image](https://user-images.githubusercontent.com/5694071/98913978-5ef36280-24c8-11eb-8eae-ce8beae52165.png)\r\n'],
                ['I noticed it is quite tricky at the moment to generate a benchmark with an unbalanced number of examples for each step.\r\nIt would be nice to have an option in ni_scenario, nc_scenario and similar to set the number of examples for each step.'],
                ['E.g.\r\n\r\n```\r\nlogger.debug("Saving {} to {}.".format(path_info, to_info))\r\n```\r\nshould be\r\n```\r\nlogger.debug("Saving \'%s\' to \'%s\'.", path_info, to_info)\r\n```\r\n\r\n~~As suggested by @ei-grad in this PR: https://github.com/iterative/dvc/pull/1822~~\r\n\r\n~~Reference: https://docs.python.org/3/howto/logging.html#optimization~~\r\n\r\n~~It needs to support braces `{}` formatting, you can use a log adapter for Python 2.7:~~\r\n<s>```python\r\nimport logging\r\n\r\nclass Message(object):\r\n    def __init__(self, fmt, args):\r\n        self.fmt = fmt\r\n        self.args = args\r\n\r\n    def __str__(self):\r\n        return self.fmt.format(*self.args)\r\n\r\nclass StyleAdapter(logging.LoggerAdapter):\r\n    def __init__(self, logger, extra=None):\r\n        super(StyleAdapter, self).__init__(logger, extra or {})\r\n\r\n    def log(self, level, msg, *args, **kwargs):\r\n        if self.isEnabledFor(level):\r\n            msg, kwargs = self.process(msg, kwargs)\r\n            self.logger._log(level, Message(msg, args), (), **kwargs)\r\n```</s>'],
                ['## Willingness to contribute\r\n\r\n- [X] Yes. I can contribute this feature independently.\r\n\r\n## Proposal Summary\r\n\r\nBy default, artifacts are stored to `./mlruns` (hard coded constant: DEFAULT_LOCAL_FILE_AND_ARTIFACT_PATH). The idea is to give the possibility to change this behaviour by setting an env var.\r\n\r\nThe same mechanism exists but not generalized:\r\n\r\n```\r\n_TRACKING_DIR_ENV_VAR = "MLFLOW_TRACKING_DIR"\r\n\r\ndef _default_root_dir():\r\n    return get_env(_TRACKING_DIR_ENV_VAR) or os.path.abspath(DEFAULT_LOCAL_FILE_AND_ARTIFACT_PATH)\r\n```'],
                ['No description provided.'],
                ["**Is your feature request related to a problem? Please describe.**\r\nPlotting confidence intervalls with the current plot function `from sktime.utils.plotting import plot_series` is not well suitable in case all lines are very close, see picture.\r\n\r\n![image](https://user-images.githubusercontent.com/29627036/102230635-6d7cd180-3eed-11eb-82b1-54bbc9f73bac.png)\r\n\r\n\r\n\r\n\r\n**Describe the solution you'd like**\r\nPlot like this would be great, with the points as an option ideally. The function could just receive the DataFrame `pred_int` from `y_pred, pred_int = model.predict(fh=fh, return_pred_int=True)\r\n` as an input so this is already well structured and named.\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/29627036/102231098-e419cf00-3eed-11eb-97ab-9101f6eaa195.png)\r\n\r\n"],
                ['Support ellipsoidal harmonics functions(https://docs.scipy.org/doc/scipy/reference/special.html#ellipsoidal-harmonics) in `tensor.special` module.'],
                ['I really like what they\'ve done here:\r\n\r\n<img width="719" alt="Screen Shot 2020-03-24 at 1 49 24 AM" src="https://user-images.githubusercontent.com/140710/77392602-b7c38e80-6d71-11ea-8d1b-df90aa5e2c09.png">\r\n\r\nhttps://nervanasystems.github.io/coach/selecting_an_algorithm.html\r\n\r\nVery user friendly. Especially helpful since the algorithms are sorted by date as well...\r\n\r\nI also find the abundance of diagrams (especially for algorithm models) to be particularly awesome:\r\n\r\n![ppo](https://user-images.githubusercontent.com/140710/77392573-aa0e0900-6d71-11ea-98cb-497e780a03e7.png)\r\n\r\nhttps://nervanasystems.github.io/coach/components/agents/policy_optimization/ppo.html'],
                ['For easier navigation, we can add the skill repository hyperlink to the following line:\r\n`We have already downloaded the data files from Kaggle and included them in the SKLL repository.` in https://skll.readthedocs.io/en/latest/tutorial.html'],
                ['Based on discussion [here](https://groups.google.com/forum/#!topic/gensim/nKVWoftW71Q), we should properly check for filename before `process calls` in `utils.check_output()`, and raise more intuitive exception and error message.\r\n\r\ncc @jayantj '],
                ['Projects, Workflows, Launch Plans, and Tasks can all have descriptions associated with them. There are endpoints that allow setting these values. But currently there is no UX for doing so in the Console.\r\n\r\nA basic implementation would be the click-to-edit pencil which saves on blur.\r\n\r\nBefore editing (pencil icon)\r\n![image](https://user-images.githubusercontent.com/1815175/73108189-7cf9c300-3eb4-11ea-9633-d9eb53ffdacb.png)\r\n\r\nEdit state with cancel/save buttons\r\n![image](https://user-images.githubusercontent.com/1815175/73108223-926eed00-3eb4-11ea-944b-e3774f1b7daf.png)\r\n\r\nDisplay of save errors goes below the buttons\r\n![image](https://user-images.githubusercontent.com/1815175/73108293-c5b17c00-3eb4-11ea-9a58-8d88a89823e5.png)\r\n\r\n'],
                ['No description provided.'],
                ['inspiration https://github.com/cs230-stanford/cs230-code-examples/tree/master/pytorch'],
                ["This is pending #22 and #314 but once it's merged we should be sure to add some examples as it's highly requested.\r\n\r\n"],
                ['about https://github.com/keras-team/keras/wiki/Keras-2.0-release-notes#training\r\n\r\n>  samples_per_epoch was renamed steps_per_epoch in fit_generator.\r\n\r\nThis description is misleading for me. This is because meaning of steps_per_epoch is totally different from of samples_per_epoch, and this is not just renaming, I think. (However, I can not propose alternative description, sorry)'],
                ['### Use case\r\n\r\nAllow to use [spacy cli](https://spacy.io/api/cli) in Polyaxon.\r\n\r\n### Feature description\r\n\r\n * Create components to run spacy cli to pretrain/train/evaluate/package models.\r\n * Create a component to run `displacy.serve` as service.\r\n * Add documentation how to store `displacy.render` using [log_html](https://polyaxon.com/docs/experimentation/tracking/module/#log_html)\r\n'],
                ["Texto atual:\r\n`At this moment, the project aims for the 100 top Brazilian municipalities by population, collecting all the gazettes since 2015. If you want to help us reach this goal, we're tracking the progress of crawlers in CITIES.md file. Have a look at it if you want to know where contributors are already working.`\r\n\r\n**Qual o problema?**\r\nO objetivo de escrever *crowlers* para as 100 cidades mais populosas não faz mais sentido para o projeto.\r\n\r\n**Qual a solução?**\r\nDefinir uma outra meta, ex: 1000 cidades aleatórias do Brasil, ou todas as cidades com mais de 100 mil habitantes."],
                ["Hello, \r\n    Considering your amazing efficiency on pandas, numpy, and more, it would seem to make sense for your module to work with even bigger data, such as Audio (for example .mp3 and .wav). This is something that would help a lot considering the nature audio (ie. where one of the lowest and most common sampling rates is still 44,100 samples/sec). For a use case, I would consider vaex.open('HugeData.mp3')"],
                ['There are a bunch of old  PRs adding spiders with no recent activity. It would be great if somebody review, fix and open a PR for them. '],
                ['Tabularizer implicitly assumes a bin width of 1, creating a column from each time point. TimeBinner generalises the Tabularizer by allowing users to specify (and tune) the bin width and aggregation function. '],
                ['<!-- Please give a clear and concise description of what the bug is: -->\r\nTrying to make a violin plot adding the seaborn hue argument will result in ValueError.\r\nIn adata, \'timepoint\' and \'replicate\' are categorical adata.obs containing floats and ints, respectively. \'timepoint\' is the age of the embryo from which cells were isolated (9.5, 10.5, etc) and \'replicate\' the number of the replica (1, 2, 3).\r\n\r\n<!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->\r\n```\r\nsc.pl.violin(adata, \'n_genes\', jitter=0.4, groupby = \'timepoint\', stripplot=False, hue=\'replicate\')\r\n```\r\n\r\n<!-- Put your Error output in this code block (if applicable, else delete the block): -->\r\n```\r\nsc.pl.violin(adata, \'n_genes\', jitter=0.4, groupby = \'timepoint\', stripplot=False, hue=\'replicate\')\r\nTraceback (most recent call last):\r\n\r\n  File "<ipython-input-5-756b321177a2>", line 1, in <module>\r\n    sc.pl.violin(adata, \'n_genes\', jitter=0.4, groupby = \'timepoint\', stripplot=False, hue=\'replicate\')\r\n\r\n  File "/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/plotting/_anndata.py", line 759, in violin\r\n    **kwds,\r\n\r\n  File "/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py", line 2393, in violinplot\r\n    color, palette, saturation)\r\n\r\n  File "/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py", line 559, in __init__\r\n    self.establish_variables(x, y, hue, data, orient, order, hue_order)\r\n\r\n  File "/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/seaborn/categorical.py", line 152, in establish_variables\r\n    raise ValueError(err)\r\n\r\nValueError: Could not interpret input \'replicate\'\r\n```\r\n\r\n#### Versions:\r\n<!-- Output of scanpy.logging.print_versions() -->\r\n> scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0'],
                ['Support {DataFrame,Series}.equals. pandas docs see https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.equals.html and https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.equals.html']
            ];
            var data = [
                ['<div><a href=https://github.com/couler-proj/couler/issues/100 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Missing documentation for some important functions', '<span class="badge badge-info">cloud-native</span> <span class="badge badge-info">workflow-management</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">distributed-computing</span> <span class="badge badge-info">kubernetes</span> <span class="badge badge-info">workflow-engine</span> <span class="badge badge-info">argo-workflows</span> <span class="badge badge-info">tekton-pipelines</span> <span class="badge badge-info">apache-airflow</span> <span class="badge badge-info">unified-interface</span> <span class="badge badge-info">unified-api</span> <span class="badge badge-info">scheduler</span> <span class="badge badge-info">workflow-automation</span> <span class="badge badge-info">kubeflow</span> <span class="badge badge-info">python</span>', '<div id=pop0>couler-proj/couler</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/RaRe-Technologies/gensim/issues/2532 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', "WordEmbeddingsKeyedVectors.add() doesn't clear `vectors_norm`, causing `IndexError` on later `most_similar()`", '<span class="badge badge-info">gensim</span> <span class="badge badge-info">topic-modeling</span> <span class="badge badge-info">information-retrieval</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">natural-language-processing</span> <span class="badge badge-info">nlp</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">python</span> <span class="badge badge-info">data-mining</span> <span class="badge badge-info">word2vec</span> <span class="badge badge-info">word-embeddings</span> <span class="badge badge-info">neural-network</span> <span class="badge badge-info">document-similarity</span> <span class="badge badge-info">word-similarity</span> <span class="badge badge-info">fasttext</span>', '<div id=pop1>RaRe-Technologies/gensim</div>', 14, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/mars-project/mars/issues/750 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Implement airy functions', '<span class="badge badge-info">python</span> <span class="badge badge-info">numpy</span> <span class="badge badge-info">tensor</span> <span class="badge badge-info">pandas</span> <span class="badge badge-info">dataframe</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">scikit-learn</span> <span class="badge badge-info">tensorflow</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">xgboost</span> <span class="badge badge-info">lightgbm</span>', '<div id=pop2>mars-project/mars</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/GPflow/GPflow/issues/1516 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Tidy empty notebooks', '<span class="badge badge-info">gaussian-processes</span> <span class="badge badge-info">tensorflow</span> <span class="badge badge-info">gpflow</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">variational-inference</span> <span class="badge badge-info">bayesian-statistics</span> <span class="badge badge-info">markov-chain-monte-carlo</span> <span class="badge badge-info">stochastic-processes</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">ml</span> <span class="badge badge-info">gp</span>', '<div id=pop3>GPflow/GPflow</div>', 4, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/lightly-ai/lightly/issues/127 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Add documentation and helper functions to store and retrieve checkpoints', '<span class="badge badge-info">deep-learning</span> <span class="badge badge-info">self-supervised-learning</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">computer-vision</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">embeddings</span>', '<div id=pop4>lightly-ai/lightly</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/mlflow/mlflow/issues/4202 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', '[DOC-FIX] Document the maximum value and legal characters for log_param, log_metric and set_tag', '<span class="badge badge-info">machine-learning</span> <span class="badge badge-info">ai</span> <span class="badge badge-info">ml</span> <span class="badge badge-info">mlflow</span> <span class="badge badge-info">apache-spark</span> <span class="badge badge-info">model-management</span>', '<div id=pop5>mlflow/mlflow</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/flyteorg/flyte/issues/524 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', '[Feature]Provide a AWS LaunchStack button for Flyte', '<span class="badge badge-info">flyte</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">golang</span> <span class="badge badge-info">scale</span> <span class="badge badge-info">workflow</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">data-analysis</span> <span class="badge badge-info">data</span> <span class="badge badge-info">kubernetes-operator</span> <span class="badge badge-info">kubernetes</span> <span class="badge badge-info">orchestration-engine</span> <span class="badge badge-info">mlops</span> <span class="badge badge-info">dataops</span> <span class="badge badge-info">grpc</span> <span class="badge badge-info">python</span> <span class="badge badge-info">battle-tested</span> <span class="badge badge-info">production</span>', '<div id=pop6>flyteorg/flyte</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/iterative/dvc/issues/2401 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', '`dvc run` suggests to run the command even with --no-exec', '<span class="badge badge-info">data-science</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">reproducibility</span> <span class="badge badge-info">data-version-control</span> <span class="badge badge-info">git</span> <span class="badge badge-info">developer-tools</span> <span class="badge badge-info">collaboration</span> <span class="badge badge-info">ai</span> <span class="badge badge-info">python</span> <span class="badge badge-info">hacktoberfest</span>', '<div id=pop7>iterative/dvc</div>', 5, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/koaning/scikit-lego/issues/292 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', '[DOCS] grouped metrics lack documentation', '<span class="badge badge-info">scikit-learn</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">common-sense</span>', '<div id=pop8>koaning/scikit-lego</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/uber/petastorm/issues/203 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'petastorm-generate-metadata.py cannot locate unischema class due to unexpected working directory', '<span class="badge badge-info">tensorflow</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">sysml</span> <span class="badge badge-info">pyspark</span> <span class="badge badge-info">pyarrow</span> <span class="badge badge-info">parquet</span> <span class="badge badge-info">parquet-files</span>', '<div id=pop9>uber/petastorm</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/PyTorchLightning/pytorch-lightning/issues/5328 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Tests refactoring - deprecating EvaluationModel', '<span class="badge badge-info">python</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">artificial-intelligence</span> <span class="badge badge-info">ai</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">machine-learning</span>', '<div id=pop10>PyTorchLightning/pytorch-lightning</div>', 2, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/replicate/keepsake/issues/302 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Mark experiment as stopped when process quits', '<span class="badge badge-info">version-control</span> <span class="badge badge-info">machine-learning</span>', '<div id=pop11>replicate/keepsake</div>', 2, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/PyTorchLightning/pytorch-lightning/issues/5023 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'fix typing in PL codebase - multiple PRs', '<span class="badge badge-info">python</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">artificial-intelligence</span> <span class="badge badge-info">ai</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">machine-learning</span>', '<div id=pop12>PyTorchLightning/pytorch-lightning</div>', 18, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/dmlc/gluon-nlp/issues/631 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Add usage example for fasttext subword embedding in Pre-trained Word Embeddings tutorial', '<span class="badge badge-info">mxnet</span> <span class="badge badge-info">gluonnlp</span> <span class="badge badge-info">nlp</span> <span class="badge badge-info">gluon</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">natural-language-processing</span> <span class="badge badge-info">numpy</span> <span class="badge badge-info">nlu</span> <span class="badge badge-info">natural-language-understanding</span> <span class="badge badge-info">nlg</span> <span class="badge badge-info">natural-language-generation</span> <span class="badge badge-info">natural-language-inference</span>', '<div id=pop13>dmlc/gluon-nlp</div>', 3, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/iver56/audiomentations/issues/50 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Add tanh distortion transform', '<span class="badge badge-info">audio</span> <span class="badge badge-info">sound</span> <span class="badge badge-info">data-augmentation</span> <span class="badge badge-info">augmentation</span> <span class="badge badge-info">sound-processing</span> <span class="badge badge-info">python</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">music</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">audio-effects</span> <span class="badge badge-info">audio-data-augmentation</span> <span class="badge badge-info">dsp</span>', '<div id=pop14>iver56/audiomentations</div>', 6, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/RaRe-Technologies/gensim/issues/1545 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Improving computational time in LDASeqModel', '<span class="badge badge-info">gensim</span> <span class="badge badge-info">topic-modeling</span> <span class="badge badge-info">information-retrieval</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">natural-language-processing</span> <span class="badge badge-info">nlp</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">python</span> <span class="badge badge-info">data-mining</span> <span class="badge badge-info">word2vec</span> <span class="badge badge-info">word-embeddings</span> <span class="badge badge-info">neural-network</span> <span class="badge badge-info">document-similarity</span> <span class="badge badge-info">word-similarity</span> <span class="badge badge-info">fasttext</span>', '<div id=pop15>RaRe-Technologies/gensim</div>', 7, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/unit8co/darts/issues/224 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Prophet return every prediction value', '<span class="badge badge-info">forecasting-models</span> <span class="badge badge-info">python</span> <span class="badge badge-info">time-series</span> <span class="badge badge-info">forecasting</span> <span class="badge badge-info">machine-learning</span>', '<div id=pop16>unit8co/darts</div>', 1, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/Cloud-CV/EvalAI/issues/3297 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Add metadata for challenges when a challenge link is shared', '<span class="badge badge-info">ai</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">django</span> <span class="badge badge-info">angularjs</span> <span class="badge badge-info">python</span> <span class="badge badge-info">ai-challenges</span> <span class="badge badge-info">docker</span> <span class="badge badge-info">reproducible-research</span> <span class="badge badge-info">reproducibility</span> <span class="badge badge-info">evaluation</span> <span class="badge badge-info">challenge</span> <span class="badge badge-info">evalai</span> <span class="badge badge-info">leaderboard</span> <span class="badge badge-info">artificial-intelligence</span> <span class="badge badge-info">angular7</span>', '<div id=pop17>Cloud-CV/EvalAI</div>', 17, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/ray-project/ray/issues/5543 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Give better error message if plasma client raises a SIGBUS signal', '<span class="badge badge-info">ray</span> <span class="badge badge-info">distributed</span> <span class="badge badge-info">parallel</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">reinforcement-learning</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">python</span> <span class="badge badge-info">rllib</span> <span class="badge badge-info">hyperparameter-search</span> <span class="badge badge-info">optimization</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">automl</span> <span class="badge badge-info">hyperparameter-optimization</span> <span class="badge badge-info">model-selection</span> <span class="badge badge-info">java</span> <span class="badge badge-info">serving</span> <span class="badge badge-info">deployment</span>', '<div id=pop18>ray-project/ray</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/awslabs/autogluon/issues/1043 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'BrokenPipeError: [Errno 32] Broken pipe', '<span class="badge badge-info">automl</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">ensemble-learning</span> <span class="badge badge-info">image-classification</span> <span class="badge badge-info">computer-vision</span> <span class="badge badge-info">natural-language-processing</span> <span class="badge badge-info">structured-data</span> <span class="badge badge-info">object-detection</span> <span class="badge badge-info">gluon</span> <span class="badge badge-info">mxnet</span> <span class="badge badge-info">transfer-learning</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">automated-machine-learning</span> <span class="badge badge-info">scikit-learn</span> <span class="badge badge-info">autogluon</span> <span class="badge badge-info">tabular-data</span> <span class="badge badge-info">neural-architecture-search</span> <span class="badge badge-info">hyperparameter-optimization</span>', '<div id=pop19>awslabs/autogluon</div>', 3, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/GPflow/GPflow/issues/1241 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Add shape asserts across code base (instead of just relying on shape comments)', '<span class="badge badge-info">gaussian-processes</span> <span class="badge badge-info">tensorflow</span> <span class="badge badge-info">gpflow</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">variational-inference</span> <span class="badge badge-info">bayesian-statistics</span> <span class="badge badge-info">markov-chain-monte-carlo</span> <span class="badge badge-info">stochastic-processes</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">ml</span> <span class="badge badge-info">gp</span>', '<div id=pop20>GPflow/GPflow</div>', 11, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/ray-project/ray/issues/8050 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', '[ui] More metadata for the task timeline', '<span class="badge badge-info">ray</span> <span class="badge badge-info">distributed</span> <span class="badge badge-info">parallel</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">reinforcement-learning</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">python</span> <span class="badge badge-info">rllib</span> <span class="badge badge-info">hyperparameter-search</span> <span class="badge badge-info">optimization</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">automl</span> <span class="badge badge-info">hyperparameter-optimization</span> <span class="badge badge-info">model-selection</span> <span class="badge badge-info">java</span> <span class="badge badge-info">serving</span> <span class="badge badge-info">deployment</span>', '<div id=pop21>ray-project/ray</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/flyteorg/flyte/issues/392 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', '[FlyteCtl] Create LaunchPlan', '<span class="badge badge-info">flyte</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">golang</span> <span class="badge badge-info">scale</span> <span class="badge badge-info">workflow</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">data-analysis</span> <span class="badge badge-info">data</span> <span class="badge badge-info">kubernetes-operator</span> <span class="badge badge-info">kubernetes</span> <span class="badge badge-info">orchestration-engine</span> <span class="badge badge-info">mlops</span> <span class="badge badge-info">dataops</span> <span class="badge badge-info">grpc</span> <span class="badge badge-info">python</span> <span class="badge badge-info">battle-tested</span> <span class="badge badge-info">production</span>', '<div id=pop22>flyteorg/flyte</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/koaning/scikit-lego/issues/457 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', "[BUG] GroupedPredictor doesn't allow for nans in input", '<span class="badge badge-info">scikit-learn</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">common-sense</span>', '<div id=pop23>koaning/scikit-lego</div>', 2, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/quic/aimet/issues/344 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Add working example for compressing a PyTorch resnet18 model using Spatial SVD', '<span class="badge badge-info">quantization</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">compression</span> <span class="badge badge-info">open-source</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">pruning</span> <span class="badge badge-info">auto-ml</span> <span class="badge badge-info">network-compression</span> <span class="badge badge-info">deep-neural-networks</span> <span class="badge badge-info">network-quantization</span> <span class="badge badge-info">opensource</span>', '<div id=pop24>quic/aimet</div>', 8, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/Neuraxio/Neuraxle/issues/303 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Feature: Should we integrate with auto-sklearn? ', '<span class="badge badge-info">pipeline</span> <span class="badge badge-info">pipeline-framework</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">framework</span> <span class="badge badge-info">python-library</span> <span class="badge badge-info">hyperparameter-optimization</span> <span class="badge badge-info">hyperparameter-tuning</span> <span class="badge badge-info">hyperparameter-search</span> <span class="badge badge-info">hyperparameters</span> <span class="badge badge-info">scikit-learn</span> <span class="badge badge-info">parallel</span> <span class="badge badge-info">neuraxle</span>', '<div id=pop25>Neuraxio/Neuraxle</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/PyTorchLightning/pytorch-lightning/issues/4409 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Remove check_val_every_n_epoch', '<span class="badge badge-info">python</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">artificial-intelligence</span> <span class="badge badge-info">ai</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">machine-learning</span>', '<div id=pop26>PyTorchLightning/pytorch-lightning</div>', 4, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/ContinualAI/avalanche/issues/487 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Add metrics to inspect dataset and patterns', '<span class="badge badge-info">continual-learning</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">neural-networks</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">artificial-intelligence</span> <span class="badge badge-info">incremental-learning</span> <span class="badge badge-info">lifelong-learning</span> <span class="badge badge-info">framework</span> <span class="badge badge-info">benchmarks</span> <span class="badge badge-info">strategies</span> <span class="badge badge-info">metrics</span> <span class="badge badge-info">continualai</span> <span class="badge badge-info">baselines</span> <span class="badge badge-info">reproducible-research</span> <span class="badge badge-info">benchmarking</span> <span class="badge badge-info">evaluation</span> <span class="badge badge-info">library</span> <span class="badge badge-info">training</span>', '<div id=pop27>ContinualAI/avalanche</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/catalyst-team/catalyst/issues/1160 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'AccuracyCallback does not work if 1 is not in topk_args', '<span class="badge badge-info">deep-learning</span> <span class="badge badge-info">reinforcement-learning</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">computer-vision</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">python</span> <span class="badge badge-info">distributed-computing</span> <span class="badge badge-info">infrastructure</span> <span class="badge badge-info">research</span> <span class="badge badge-info">reproducibility</span> <span class="badge badge-info">image-processing</span> <span class="badge badge-info">image-classification</span> <span class="badge badge-info">image-segmentation</span> <span class="badge badge-info">object-detection</span> <span class="badge badge-info">natural-language-processing</span> <span class="badge badge-info">text-classification</span> <span class="badge badge-info">text-segmentation</span> <span class="badge badge-info">information-retrieval</span> <span class="badge badge-info">recommender-system</span> <span class="badge badge-info">metric-learning</span>', '<div id=pop28>catalyst-team/catalyst</div>', 2, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/elyra-ai/elyra/issues/710 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Pipeline node properties does not recognize new environment variables', '<span class="badge badge-info">notebooks</span> <span class="badge badge-info">notebook-jupyter</span> <span class="badge badge-info">jupyterlab</span> <span class="badge badge-info">jupyterlab-extensions</span> <span class="badge badge-info">ai</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">pipelines</span> <span class="badge badge-info">kubeflow-pipelines</span> <span class="badge badge-info">python</span> <span class="badge badge-info">elyra</span> <span class="badge badge-info">binder</span> <span class="badge badge-info">jupyterlab-notebooks</span> <span class="badge badge-info">kubeflow</span> <span class="badge badge-info">hacktoberfest</span> <span class="badge badge-info">jupyterlab-extension</span> <span class="badge badge-info">anaconda</span> <span class="badge badge-info">pypi</span> <span class="badge badge-info">docker</span> <span class="badge badge-info">apache-airflow</span> <span class="badge badge-info">airflow</span>', '<div id=pop29>elyra-ai/elyra</div>', 11, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/skorch-dev/skorch/issues/291 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Print param groups after initialization', '<span class="badge badge-info">scikit-learn</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">machine-learning</span>', '<div id=pop30>skorch-dev/skorch</div>', 3, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/keras-team/keras/issues/8510 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'CuDNNLSTM and activations', '<span class="badge badge-info">deep-learning</span> <span class="badge badge-info">tensorflow</span> <span class="badge badge-info">neural-networks</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">python</span>', '<div id=pop31>keras-team/keras</div>', 10, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/ContinualAI/avalanche/issues/557 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Uniform API for classic Benchmarks', '<span class="badge badge-info">continual-learning</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">neural-networks</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">artificial-intelligence</span> <span class="badge badge-info">incremental-learning</span> <span class="badge badge-info">lifelong-learning</span> <span class="badge badge-info">framework</span> <span class="badge badge-info">benchmarks</span> <span class="badge badge-info">strategies</span> <span class="badge badge-info">metrics</span> <span class="badge badge-info">continualai</span> <span class="badge badge-info">baselines</span> <span class="badge badge-info">reproducible-research</span> <span class="badge badge-info">benchmarking</span> <span class="badge badge-info">evaluation</span> <span class="badge badge-info">library</span> <span class="badge badge-info">training</span>', '<div id=pop32>ContinualAI/avalanche</div>', 1, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/scikit-learn/scikit-learn/issues/13117 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Possible error in documentation of ElasticNetCV()', '<span class="badge badge-info">machine-learning</span> <span class="badge badge-info">python</span> <span class="badge badge-info">statistics</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">data-analysis</span>', '<div id=pop33>scikit-learn/scikit-learn</div>', 6, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/nilearn/nilearn/issues/1145 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Add Juelich atlas', '<span class="badge badge-info">python</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">fmri</span> <span class="badge badge-info">neuroimaging</span> <span class="badge badge-info">mvpa</span> <span class="badge badge-info">decoding</span> <span class="badge badge-info">brain-connectivity</span> <span class="badge badge-info">brain-imaging</span> <span class="badge badge-info">brain-mri</span>', '<div id=pop34>nilearn/nilearn</div>', 5, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/ray-project/ray/issues/8450 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Ray Dashboard Head-node CLI [autoscaler]', '<span class="badge badge-info">ray</span> <span class="badge badge-info">distributed</span> <span class="badge badge-info">parallel</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">reinforcement-learning</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">python</span> <span class="badge badge-info">rllib</span> <span class="badge badge-info">hyperparameter-search</span> <span class="badge badge-info">optimization</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">automl</span> <span class="badge badge-info">hyperparameter-optimization</span> <span class="badge badge-info">model-selection</span> <span class="badge badge-info">java</span> <span class="badge badge-info">serving</span> <span class="badge badge-info">deployment</span>', '<div id=pop35>ray-project/ray</div>', 3, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/vwxyzjn/cleanrl/issues/29 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Support Procgen Environments', '<span class="badge badge-info">wandb</span> <span class="badge badge-info">reinforcement-learning</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">python</span> <span class="badge badge-info">gym</span> <span class="badge badge-info">machine-learning</span>', '<div id=pop36>vwxyzjn/cleanrl</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/optuna/optuna/issues/517 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Add a guideline to setup RDB with Docker.', '<span class="badge badge-info">python</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">parallel</span> <span class="badge badge-info">distributed</span> <span class="badge badge-info">hyperparameter-optimization</span>', '<div id=pop37>optuna/optuna</div>', 4, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/mlflow/mlflow/issues/4055 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', '[BUG] infer_signature fails when dataframe contains ExtensionDtype', '<span class="badge badge-info">machine-learning</span> <span class="badge badge-info">ai</span> <span class="badge badge-info">ml</span> <span class="badge badge-info">mlflow</span> <span class="badge badge-info">apache-spark</span> <span class="badge badge-info">model-management</span>', '<div id=pop38>mlflow/mlflow</div>', 4, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/theislab/scanpy/issues/1203 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', "sc.pl.paga: TypeError: paga() got an unexpected keyword argument 'ncols'", '<span class="badge badge-info">machine-learning</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">visualize-data</span> <span class="badge badge-info">transcriptomics</span> <span class="badge badge-info">bioinformatics</span> <span class="badge badge-info">scanpy</span> <span class="badge badge-info">anndata</span>', '<div id=pop39>theislab/scanpy</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/vaexio/vaex/issues/912 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', '[FEATURE-REQUEST] Support netCDF-4 files', '<span class="badge badge-info">dataframe</span> <span class="badge badge-info">python</span> <span class="badge badge-info">bigdata</span> <span class="badge badge-info">tabular-data</span> <span class="badge badge-info">visualization</span> <span class="badge badge-info">memory-mapped-file</span> <span class="badge badge-info">hdf5</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">machinelearning</span>', '<div id=pop40>vaexio/vaex</div>', 7, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/RaRe-Technologies/gensim/issues/1171 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'BleiCorpus after serialize cannot be loaded', '<span class="badge badge-info">gensim</span> <span class="badge badge-info">topic-modeling</span> <span class="badge badge-info">information-retrieval</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">natural-language-processing</span> <span class="badge badge-info">nlp</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">python</span> <span class="badge badge-info">data-mining</span> <span class="badge badge-info">word2vec</span> <span class="badge badge-info">word-embeddings</span> <span class="badge badge-info">neural-network</span> <span class="badge badge-info">document-similarity</span> <span class="badge badge-info">word-similarity</span> <span class="badge badge-info">fasttext</span>', '<div id=pop41>RaRe-Technologies/gensim</div>', 30, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/orchest/orchest/issues/177 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', "Set default values for Orchest's configuration in the internal library", '<span class="badge badge-info">data-science</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">pipelines</span> <span class="badge badge-info">ide</span> <span class="badge badge-info">jupyter</span> <span class="badge badge-info">cloud</span> <span class="badge badge-info">self-hosted</span>', '<div id=pop42>orchest/orchest</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/nilearn/nilearn/issues/2412 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', '[Question] Using RGBA value from FreeSurfer LUT to plot ROI', '<span class="badge badge-info">python</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">fmri</span> <span class="badge badge-info">neuroimaging</span> <span class="badge badge-info">mvpa</span> <span class="badge badge-info">decoding</span> <span class="badge badge-info">brain-connectivity</span> <span class="badge badge-info">brain-imaging</span> <span class="badge badge-info">brain-mri</span>', '<div id=pop43>nilearn/nilearn</div>', 7, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/optuna/optuna/issues/1683 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Improve the search space of XGBoost example.', '<span class="badge badge-info">python</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">parallel</span> <span class="badge badge-info">distributed</span> <span class="badge badge-info">hyperparameter-optimization</span>', '<div id=pop44>optuna/optuna</div>', 5, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/flyteorg/flyte/issues/701 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', '[Feature][Flytekit Schema type extension] Vaex Dataframe plugin', '<span class="badge badge-info">flyte</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">golang</span> <span class="badge badge-info">scale</span> <span class="badge badge-info">workflow</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">data-analysis</span> <span class="badge badge-info">data</span> <span class="badge badge-info">kubernetes-operator</span> <span class="badge badge-info">kubernetes</span> <span class="badge badge-info">orchestration-engine</span> <span class="badge badge-info">mlops</span> <span class="badge badge-info">dataops</span> <span class="badge badge-info">grpc</span> <span class="badge badge-info">python</span> <span class="badge badge-info">battle-tested</span> <span class="badge badge-info">production</span>', '<div id=pop45>flyteorg/flyte</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/ContinualAI/avalanche/issues/213 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Add (Diaz-Rodriguez, 2018) metrics: A, MS, SSS, CE, CLscore & CLstability', '<span class="badge badge-info">continual-learning</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">neural-networks</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">artificial-intelligence</span> <span class="badge badge-info">incremental-learning</span> <span class="badge badge-info">lifelong-learning</span> <span class="badge badge-info">framework</span> <span class="badge badge-info">benchmarks</span> <span class="badge badge-info">strategies</span> <span class="badge badge-info">metrics</span> <span class="badge badge-info">continualai</span> <span class="badge badge-info">baselines</span> <span class="badge badge-info">reproducible-research</span> <span class="badge badge-info">benchmarking</span> <span class="badge badge-info">evaluation</span> <span class="badge badge-info">library</span> <span class="badge badge-info">training</span>', '<div id=pop46>ContinualAI/avalanche</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/flyteorg/flyte/issues/401 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', '[FlyteCtl] Update MatchableEntity', '<span class="badge badge-info">flyte</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">golang</span> <span class="badge badge-info">scale</span> <span class="badge badge-info">workflow</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">data-analysis</span> <span class="badge badge-info">data</span> <span class="badge badge-info">kubernetes-operator</span> <span class="badge badge-info">kubernetes</span> <span class="badge badge-info">orchestration-engine</span> <span class="badge badge-info">mlops</span> <span class="badge badge-info">dataops</span> <span class="badge badge-info">grpc</span> <span class="badge badge-info">python</span> <span class="badge badge-info">battle-tested</span> <span class="badge badge-info">production</span>', '<div id=pop47>flyteorg/flyte</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/dmlc/gluon-cv/issues/331 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Resuming from checkpoints for classification scripts', '<span class="badge badge-info">deep-learning</span> <span class="badge badge-info">computer-vision</span> <span class="badge badge-info">neural-network</span> <span class="badge badge-info">gluon</span> <span class="badge badge-info">mxnet</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">image-classification</span> <span class="badge badge-info">object-detection</span> <span class="badge badge-info">semantic-segmentation</span> <span class="badge badge-info">gan</span> <span class="badge badge-info">person-reid</span> <span class="badge badge-info">action-recognition</span> <span class="badge badge-info">pose-estimation</span>', '<div id=pop48>dmlc/gluon-cv</div>', 3, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/optuna/optuna/issues/852 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Warn multiple intermediate value reports with the same step.', '<span class="badge badge-info">python</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">parallel</span> <span class="badge badge-info">distributed</span> <span class="badge badge-info">hyperparameter-optimization</span>', '<div id=pop49>optuna/optuna</div>', 8, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/online-ml/river/issues/400 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Activating mypy on CI', '<span class="badge badge-info">incremental-learning</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">python</span> <span class="badge badge-info">online-learning</span> <span class="badge badge-info">online-statistics</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">streaming</span> <span class="badge badge-info">online-machine-learning</span> <span class="badge badge-info">streaming-data</span> <span class="badge badge-info">concept-drift</span>', '<div id=pop50>online-ml/river</div>', 1, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/Trusted-AI/AIF360/issues/150 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Port micellaneous items to sklearn-compatible API', '<span class="badge badge-info">ai</span> <span class="badge badge-info">fairness-ai</span> <span class="badge badge-info">fairness</span> <span class="badge badge-info">fairness-testing</span> <span class="badge badge-info">fairness-awareness-model</span> <span class="badge badge-info">bias-detection</span> <span class="badge badge-info">bias</span> <span class="badge badge-info">bias-correction</span> <span class="badge badge-info">bias-reduction</span> <span class="badge badge-info">bias-finder</span> <span class="badge badge-info">artificial-intelligence</span> <span class="badge badge-info">discrimination</span> <span class="badge badge-info">ibm-research-ai</span> <span class="badge badge-info">ibm-research</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">codait</span> <span class="badge badge-info">trusted-ai</span> <span class="badge badge-info">r</span> <span class="badge badge-info">python</span>', '<div id=pop51>Trusted-AI/AIF360</div>', 3, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/dmlc/gluon-nlp/issues/1401 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', '[TVM Integration] Improve TVM Integration: Tutorial + Investigating Numerical Issue ', '<span class="badge badge-info">mxnet</span> <span class="badge badge-info">gluonnlp</span> <span class="badge badge-info">nlp</span> <span class="badge badge-info">gluon</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">natural-language-processing</span> <span class="badge badge-info">numpy</span> <span class="badge badge-info">nlu</span> <span class="badge badge-info">natural-language-understanding</span> <span class="badge badge-info">nlg</span> <span class="badge badge-info">natural-language-generation</span> <span class="badge badge-info">natural-language-inference</span>', '<div id=pop52>dmlc/gluon-nlp</div>', 1, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/tensorflow/addons/issues/258 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Fork Keras Layer Test ', '<span class="badge badge-info">machine-learning</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">tensorflow</span> <span class="badge badge-info">neural-network</span> <span class="badge badge-info">tensorflow-addons</span> <span class="badge badge-info">python</span>', '<div id=pop53>tensorflow/addons</div>', 5, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/nilearn/nilearn/issues/1737 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Too many deprecation warnings cluttering the outputs', '<span class="badge badge-info">python</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">fmri</span> <span class="badge badge-info">neuroimaging</span> <span class="badge badge-info">mvpa</span> <span class="badge badge-info">decoding</span> <span class="badge badge-info">brain-connectivity</span> <span class="badge badge-info">brain-imaging</span> <span class="badge badge-info">brain-mri</span>', '<div id=pop54>nilearn/nilearn</div>', 1, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/Neuraxio/Neuraxle/issues/416 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Bug: Put testing files in the right testing package (same as the lib packages)', '<span class="badge badge-info">pipeline</span> <span class="badge badge-info">pipeline-framework</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">framework</span> <span class="badge badge-info">python-library</span> <span class="badge badge-info">hyperparameter-optimization</span> <span class="badge badge-info">hyperparameter-tuning</span> <span class="badge badge-info">hyperparameter-search</span> <span class="badge badge-info">hyperparameters</span> <span class="badge badge-info">scikit-learn</span> <span class="badge badge-info">parallel</span> <span class="badge badge-info">neuraxle</span>', '<div id=pop55>Neuraxio/Neuraxle</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/PyTorchLightning/pytorch-lightning/issues/4536 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Create an Enum for tracking Train, validation, test stage ', '<span class="badge badge-info">python</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">artificial-intelligence</span> <span class="badge badge-info">ai</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">machine-learning</span>', '<div id=pop56>PyTorchLightning/pytorch-lightning</div>', 2, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/ourownstory/neural_prophet/issues/53 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'fail with specific error message when data contains duplicate date entries.', '<span class="badge badge-info">forecasting</span> <span class="badge badge-info">time-series</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">fbprophet</span> <span class="badge badge-info">prophet</span> <span class="badge badge-info">forecast</span> <span class="badge badge-info">artificial-intelligence</span> <span class="badge badge-info">prediction</span> <span class="badge badge-info">trend</span> <span class="badge badge-info">seasonality</span> <span class="badge badge-info">autoregression</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">timeseries</span> <span class="badge badge-info">forecasting-algorithm</span> <span class="badge badge-info">forecasting-model</span> <span class="badge badge-info">neuralprophet</span> <span class="badge badge-info">neural</span> <span class="badge badge-info">neural-network</span>', '<div id=pop57>ourownstory/neural_prophet</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/GPflow/GPflow/issues/1604 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', "Support TFP's (L-)BFGS optimiser", '<span class="badge badge-info">gaussian-processes</span> <span class="badge badge-info">tensorflow</span> <span class="badge badge-info">gpflow</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">variational-inference</span> <span class="badge badge-info">bayesian-statistics</span> <span class="badge badge-info">markov-chain-monte-carlo</span> <span class="badge badge-info">stochastic-processes</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">ml</span> <span class="badge badge-info">gp</span>', '<div id=pop58>GPflow/GPflow</div>', 2, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/Cloud-CV/EvalAI/issues/1558 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Add constraints for setting challenge phase start and end date', '<span class="badge badge-info">ai</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">django</span> <span class="badge badge-info">angularjs</span> <span class="badge badge-info">python</span> <span class="badge badge-info">ai-challenges</span> <span class="badge badge-info">docker</span> <span class="badge badge-info">reproducible-research</span> <span class="badge badge-info">reproducibility</span> <span class="badge badge-info">evaluation</span> <span class="badge badge-info">challenge</span> <span class="badge badge-info">evalai</span> <span class="badge badge-info">leaderboard</span> <span class="badge badge-info">artificial-intelligence</span> <span class="badge badge-info">angular7</span>', '<div id=pop59>Cloud-CV/EvalAI</div>', 16, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/nilearn/nilearn/issues/1397 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'wish list: locate the peaks (maxima) in a volume', '<span class="badge badge-info">python</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">fmri</span> <span class="badge badge-info">neuroimaging</span> <span class="badge badge-info">mvpa</span> <span class="badge badge-info">decoding</span> <span class="badge badge-info">brain-connectivity</span> <span class="badge badge-info">brain-imaging</span> <span class="badge badge-info">brain-mri</span>', '<div id=pop60>nilearn/nilearn</div>', 3, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/aimhubio/aim/issues/339 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Edit and export charts as SVG, PNG', '<span class="badge badge-info">machine-learning</span> <span class="badge badge-info">training-tracking</span> <span class="badge badge-info">experiment-tracking</span> <span class="badge badge-info">mlops</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">tensorflow</span> <span class="badge badge-info">keras</span> <span class="badge badge-info">pytorch-lightning</span> <span class="badge badge-info">nlp</span> <span class="badge badge-info">reinforcement-learning</span>', '<div id=pop61>aimhubio/aim</div>', 9, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/couler-proj/couler/issues/84 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Upgrade to use environment files for GitHub Actions', '<span class="badge badge-info">cloud-native</span> <span class="badge badge-info">workflow-management</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">distributed-computing</span> <span class="badge badge-info">kubernetes</span> <span class="badge badge-info">workflow-engine</span> <span class="badge badge-info">argo-workflows</span> <span class="badge badge-info">tekton-pipelines</span> <span class="badge badge-info">apache-airflow</span> <span class="badge badge-info">unified-interface</span> <span class="badge badge-info">unified-api</span> <span class="badge badge-info">scheduler</span> <span class="badge badge-info">workflow-automation</span> <span class="badge badge-info">kubeflow</span> <span class="badge badge-info">python</span>', '<div id=pop62>couler-proj/couler</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/GPflow/GPflow/issues/1345 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Proposal: beyond mean&var for non-Gaussian likelihoods', '<span class="badge badge-info">gaussian-processes</span> <span class="badge badge-info">tensorflow</span> <span class="badge badge-info">gpflow</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">variational-inference</span> <span class="badge badge-info">bayesian-statistics</span> <span class="badge badge-info">markov-chain-monte-carlo</span> <span class="badge badge-info">stochastic-processes</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">ml</span> <span class="badge badge-info">gp</span>', '<div id=pop63>GPflow/GPflow</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/dmlc/gluon-cv/issues/281 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Any easier tutorial for custom object detection?', '<span class="badge badge-info">deep-learning</span> <span class="badge badge-info">computer-vision</span> <span class="badge badge-info">neural-network</span> <span class="badge badge-info">gluon</span> <span class="badge badge-info">mxnet</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">image-classification</span> <span class="badge badge-info">object-detection</span> <span class="badge badge-info">semantic-segmentation</span> <span class="badge badge-info">gan</span> <span class="badge badge-info">person-reid</span> <span class="badge badge-info">action-recognition</span> <span class="badge badge-info">pose-estimation</span>', '<div id=pop64>dmlc/gluon-cv</div>', 3, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/yzhao062/pyod/issues/150 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'callbacks in autoencoder', '<span class="badge badge-info">outlier-detection</span> <span class="badge badge-info">anomaly-detection</span> <span class="badge badge-info">outlier-ensembles</span> <span class="badge badge-info">outliers</span> <span class="badge badge-info">anomaly</span> <span class="badge badge-info">python</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">data-mining</span> <span class="badge badge-info">unsupervised-learning</span> <span class="badge badge-info">python2</span> <span class="badge badge-info">python3</span> <span class="badge badge-info">fraud-detection</span> <span class="badge badge-info">autoencoder</span> <span class="badge badge-info">neural-networks</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">data-analysis</span>', '<div id=pop65>yzhao062/pyod</div>', 3, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/larq/larq/issues/309 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'RFC: Use type hints in larq source code', '<span class="badge badge-info">deep-learning</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">tensorflow</span> <span class="badge badge-info">python</span> <span class="badge badge-info">binarized-neural-networks</span> <span class="badge badge-info">quantized-neural-networks</span> <span class="badge badge-info">keras</span> <span class="badge badge-info">binder</span> <span class="badge badge-info">larq</span>', '<div id=pop66>larq/larq</div>', 8, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/flyteorg/flyte/issues/402 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', '[FlyteCtl] Create Outputs', '<span class="badge badge-info">flyte</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">golang</span> <span class="badge badge-info">scale</span> <span class="badge badge-info">workflow</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">data-analysis</span> <span class="badge badge-info">data</span> <span class="badge badge-info">kubernetes-operator</span> <span class="badge badge-info">kubernetes</span> <span class="badge badge-info">orchestration-engine</span> <span class="badge badge-info">mlops</span> <span class="badge badge-info">dataops</span> <span class="badge badge-info">grpc</span> <span class="badge badge-info">python</span> <span class="badge badge-info">battle-tested</span> <span class="badge badge-info">production</span>', '<div id=pop67>flyteorg/flyte</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/ray-project/ray/issues/9384 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Option to surpress large number of actors warning', '<span class="badge badge-info">ray</span> <span class="badge badge-info">distributed</span> <span class="badge badge-info">parallel</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">reinforcement-learning</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">python</span> <span class="badge badge-info">rllib</span> <span class="badge badge-info">hyperparameter-search</span> <span class="badge badge-info">optimization</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">automl</span> <span class="badge badge-info">hyperparameter-optimization</span> <span class="badge badge-info">model-selection</span> <span class="badge badge-info">java</span> <span class="badge badge-info">serving</span> <span class="badge badge-info">deployment</span>', '<div id=pop68>ray-project/ray</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/pykeen/pykeen/issues/82 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Update models using complex numbers', '<span class="badge badge-info">knowledge-graph-embeddings</span> <span class="badge badge-info">knowledge-graphs</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">link-prediction</span> <span class="badge badge-info">knowledge-base-completion</span> <span class="badge badge-info">pykeen</span>', '<div id=pop69>pykeen/pykeen</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/nilearn/nilearn/issues/2763 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Multiple definitions of `basic_paradigm`', '<span class="badge badge-info">python</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">fmri</span> <span class="badge badge-info">neuroimaging</span> <span class="badge badge-info">mvpa</span> <span class="badge badge-info">decoding</span> <span class="badge badge-info">brain-connectivity</span> <span class="badge badge-info">brain-imaging</span> <span class="badge badge-info">brain-mri</span>', '<div id=pop70>nilearn/nilearn</div>', 2, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/iterative/dvc/issues/2613 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'get/import: consider lstrip("/") for data path', '<span class="badge badge-info">data-science</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">reproducibility</span> <span class="badge badge-info">data-version-control</span> <span class="badge badge-info">git</span> <span class="badge badge-info">developer-tools</span> <span class="badge badge-info">collaboration</span> <span class="badge badge-info">ai</span> <span class="badge badge-info">python</span> <span class="badge badge-info">hacktoberfest</span>', '<div id=pop71>iterative/dvc</div>', 16, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/ray-project/ray/issues/10598 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Ray health check', '<span class="badge badge-info">ray</span> <span class="badge badge-info">distributed</span> <span class="badge badge-info">parallel</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">reinforcement-learning</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">python</span> <span class="badge badge-info">rllib</span> <span class="badge badge-info">hyperparameter-search</span> <span class="badge badge-info">optimization</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">automl</span> <span class="badge badge-info">hyperparameter-optimization</span> <span class="badge badge-info">model-selection</span> <span class="badge badge-info">java</span> <span class="badge badge-info">serving</span> <span class="badge badge-info">deployment</span>', '<div id=pop72>ray-project/ray</div>', 9, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/couler-proj/couler/issues/32 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Support multiple function arguments in `couler.map()`', '<span class="badge badge-info">cloud-native</span> <span class="badge badge-info">workflow-management</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">distributed-computing</span> <span class="badge badge-info">kubernetes</span> <span class="badge badge-info">workflow-engine</span> <span class="badge badge-info">argo-workflows</span> <span class="badge badge-info">tekton-pipelines</span> <span class="badge badge-info">apache-airflow</span> <span class="badge badge-info">unified-interface</span> <span class="badge badge-info">unified-api</span> <span class="badge badge-info">scheduler</span> <span class="badge badge-info">workflow-automation</span> <span class="badge badge-info">kubeflow</span> <span class="badge badge-info">python</span>', '<div id=pop73>couler-proj/couler</div>', 2, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/lightly-ai/lightly/issues/264 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Add multi-modal loss', '<span class="badge badge-info">deep-learning</span> <span class="badge badge-info">self-supervised-learning</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">computer-vision</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">embeddings</span>', '<div id=pop74>lightly-ai/lightly</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/alan-turing-institute/sktime/issues/745 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Directional forecasting ', '<span class="badge badge-info">time-series</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">scikit-learn</span> <span class="badge badge-info">time-series-classification</span> <span class="badge badge-info">time-series-regression</span> <span class="badge badge-info">forecasting</span> <span class="badge badge-info">time-series-analysis</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">data-mining</span>', '<div id=pop75>alan-turing-institute/sktime</div>', 7, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/iterative/dvc/issues/2696 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'update: improve output when import stage is fixed to an unchanged rev?', '<span class="badge badge-info">data-science</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">reproducibility</span> <span class="badge badge-info">data-version-control</span> <span class="badge badge-info">git</span> <span class="badge badge-info">developer-tools</span> <span class="badge badge-info">collaboration</span> <span class="badge badge-info">ai</span> <span class="badge badge-info">python</span> <span class="badge badge-info">hacktoberfest</span>', '<div id=pop76>iterative/dvc</div>', 8, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/catalyst-team/catalyst/issues/1161 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Add Classifier-Balancing to catalyst.data API', '<span class="badge badge-info">deep-learning</span> <span class="badge badge-info">reinforcement-learning</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">computer-vision</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">python</span> <span class="badge badge-info">distributed-computing</span> <span class="badge badge-info">infrastructure</span> <span class="badge badge-info">research</span> <span class="badge badge-info">reproducibility</span> <span class="badge badge-info">image-processing</span> <span class="badge badge-info">image-classification</span> <span class="badge badge-info">image-segmentation</span> <span class="badge badge-info">object-detection</span> <span class="badge badge-info">natural-language-processing</span> <span class="badge badge-info">text-classification</span> <span class="badge badge-info">text-segmentation</span> <span class="badge badge-info">information-retrieval</span> <span class="badge badge-info">recommender-system</span> <span class="badge badge-info">metric-learning</span>', '<div id=pop77>catalyst-team/catalyst</div>', 3, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/elyra-ai/elyra/issues/1066 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Import/export functionality for runtime configurations', '<span class="badge badge-info">notebooks</span> <span class="badge badge-info">notebook-jupyter</span> <span class="badge badge-info">jupyterlab</span> <span class="badge badge-info">jupyterlab-extensions</span> <span class="badge badge-info">ai</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">pipelines</span> <span class="badge badge-info">kubeflow-pipelines</span> <span class="badge badge-info">python</span> <span class="badge badge-info">elyra</span> <span class="badge badge-info">binder</span> <span class="badge badge-info">jupyterlab-notebooks</span> <span class="badge badge-info">kubeflow</span> <span class="badge badge-info">hacktoberfest</span> <span class="badge badge-info">jupyterlab-extension</span> <span class="badge badge-info">anaconda</span> <span class="badge badge-info">pypi</span> <span class="badge badge-info">docker</span> <span class="badge badge-info">apache-airflow</span> <span class="badge badge-info">airflow</span>', '<div id=pop78>elyra-ai/elyra</div>', 3, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/ContinualAI/avalanche/issues/331 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Unbalanced Steps Sizes Option for Benchmarks Generators', '<span class="badge badge-info">continual-learning</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">neural-networks</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">artificial-intelligence</span> <span class="badge badge-info">incremental-learning</span> <span class="badge badge-info">lifelong-learning</span> <span class="badge badge-info">framework</span> <span class="badge badge-info">benchmarks</span> <span class="badge badge-info">strategies</span> <span class="badge badge-info">metrics</span> <span class="badge badge-info">continualai</span> <span class="badge badge-info">baselines</span> <span class="badge badge-info">reproducible-research</span> <span class="badge badge-info">benchmarking</span> <span class="badge badge-info">evaluation</span> <span class="badge badge-info">library</span> <span class="badge badge-info">training</span>', '<div id=pop79>ContinualAI/avalanche</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/iterative/dvc/issues/1843 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'logger: use logging format interpolation', '<span class="badge badge-info">data-science</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">reproducibility</span> <span class="badge badge-info">data-version-control</span> <span class="badge badge-info">git</span> <span class="badge badge-info">developer-tools</span> <span class="badge badge-info">collaboration</span> <span class="badge badge-info">ai</span> <span class="badge badge-info">python</span> <span class="badge badge-info">hacktoberfest</span>', '<div id=pop80>iterative/dvc</div>', 3, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/mlflow/mlflow/issues/4077 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', '[FR] No way to configure artifact store path when tracking on SQLAlchemy', '<span class="badge badge-info">machine-learning</span> <span class="badge badge-info">ai</span> <span class="badge badge-info">ml</span> <span class="badge badge-info">mlflow</span> <span class="badge badge-info">apache-spark</span> <span class="badge badge-info">model-management</span>', '<div id=pop81>mlflow/mlflow</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/Neuraxio/Neuraxle/issues/210 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Feature: Ctor of Hp Space should validate that each object is of type Distribution.', '<span class="badge badge-info">pipeline</span> <span class="badge badge-info">pipeline-framework</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">framework</span> <span class="badge badge-info">python-library</span> <span class="badge badge-info">hyperparameter-optimization</span> <span class="badge badge-info">hyperparameter-tuning</span> <span class="badge badge-info">hyperparameter-search</span> <span class="badge badge-info">hyperparameters</span> <span class="badge badge-info">scikit-learn</span> <span class="badge badge-info">parallel</span> <span class="badge badge-info">neuraxle</span>', '<div id=pop82>Neuraxio/Neuraxle</div>', 1, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/alan-turing-institute/sktime/issues/541 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Plotting confidence intervals', '<span class="badge badge-info">time-series</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">scikit-learn</span> <span class="badge badge-info">time-series-classification</span> <span class="badge badge-info">time-series-regression</span> <span class="badge badge-info">forecasting</span> <span class="badge badge-info">time-series-analysis</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">data-mining</span>', '<div id=pop83>alan-turing-institute/sktime</div>', 10, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/mars-project/mars/issues/758 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Implement ellipsoidal harmonics functions', '<span class="badge badge-info">python</span> <span class="badge badge-info">numpy</span> <span class="badge badge-info">tensor</span> <span class="badge badge-info">pandas</span> <span class="badge badge-info">dataframe</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">scikit-learn</span> <span class="badge badge-info">tensorflow</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">xgboost</span> <span class="badge badge-info">lightgbm</span>', '<div id=pop84>mars-project/mars</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/ray-project/ray/issues/7722 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Awesome: algorithm selection helper & diagrams', '<span class="badge badge-info">ray</span> <span class="badge badge-info">distributed</span> <span class="badge badge-info">parallel</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">reinforcement-learning</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">python</span> <span class="badge badge-info">rllib</span> <span class="badge badge-info">hyperparameter-search</span> <span class="badge badge-info">optimization</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">automl</span> <span class="badge badge-info">hyperparameter-optimization</span> <span class="badge badge-info">model-selection</span> <span class="badge badge-info">java</span> <span class="badge badge-info">serving</span> <span class="badge badge-info">deployment</span>', '<div id=pop85>ray-project/ray</div>', 1, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/EducationalTestingService/skll/issues/688 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Hyperlink skll repo in the tutorial documentation', '<span class="badge badge-info">machine-learning</span> <span class="badge badge-info">python</span> <span class="badge badge-info">scikit-learn</span> <span class="badge badge-info">hacktoberfest</span>', '<div id=pop86>EducationalTestingService/skll</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/RaRe-Technologies/gensim/issues/1485 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'proper check for filename before calling subprocess', '<span class="badge badge-info">gensim</span> <span class="badge badge-info">topic-modeling</span> <span class="badge badge-info">information-retrieval</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">natural-language-processing</span> <span class="badge badge-info">nlp</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">python</span> <span class="badge badge-info">data-mining</span> <span class="badge badge-info">word2vec</span> <span class="badge badge-info">word-embeddings</span> <span class="badge badge-info">neural-network</span> <span class="badge badge-info">document-similarity</span> <span class="badge badge-info">word-similarity</span> <span class="badge badge-info">fasttext</span>', '<div id=pop87>RaRe-Technologies/gensim</div>', 10, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/flyteorg/flyte/issues/145 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Allow editing of descriptions via the UI', '<span class="badge badge-info">flyte</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">golang</span> <span class="badge badge-info">scale</span> <span class="badge badge-info">workflow</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">data-analysis</span> <span class="badge badge-info">data</span> <span class="badge badge-info">kubernetes-operator</span> <span class="badge badge-info">kubernetes</span> <span class="badge badge-info">orchestration-engine</span> <span class="badge badge-info">mlops</span> <span class="badge badge-info">dataops</span> <span class="badge badge-info">grpc</span> <span class="badge badge-info">python</span> <span class="badge badge-info">battle-tested</span> <span class="badge badge-info">production</span>', '<div id=pop88>flyteorg/flyte</div>', 8, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/fepegar/torchio/issues/81 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Randomize k-space filling axis in RandomMotion', '<span class="badge badge-info">pytorch</span> <span class="badge badge-info">medical-image-computing</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">convolutional-neural-networks</span> <span class="badge badge-info">data-augmentation</span> <span class="badge badge-info">medical-images</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">cnn</span> <span class="badge badge-info">segmentation</span> <span class="badge badge-info">python</span> <span class="badge badge-info">medical-image-processing</span> <span class="badge badge-info">medical-image-analysis</span> <span class="badge badge-info">medical-imaging</span> <span class="badge badge-info">medical-imaging-datasets</span> <span class="badge badge-info">medical-imaging-with-deep-learning</span> <span class="badge badge-info">augmentation</span> <span class="badge badge-info">preprocess</span> <span class="badge badge-info">computer-vision</span>', '<div id=pop89>fepegar/torchio</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/ourownstory/neural_prophet/issues/27 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'add model saving/loading functions', '<span class="badge badge-info">forecasting</span> <span class="badge badge-info">time-series</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">fbprophet</span> <span class="badge badge-info">prophet</span> <span class="badge badge-info">forecast</span> <span class="badge badge-info">artificial-intelligence</span> <span class="badge badge-info">prediction</span> <span class="badge badge-info">trend</span> <span class="badge badge-info">seasonality</span> <span class="badge badge-info">autoregression</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">timeseries</span> <span class="badge badge-info">forecasting-algorithm</span> <span class="badge badge-info">forecasting-model</span> <span class="badge badge-info">neuralprophet</span> <span class="badge badge-info">neural</span> <span class="badge badge-info">neural-network</span>', '<div id=pop90>ourownstory/neural_prophet</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/tensorflow/addons/issues/337 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Request for example: CRF', '<span class="badge badge-info">machine-learning</span> <span class="badge badge-info">deep-learning</span> <span class="badge badge-info">tensorflow</span> <span class="badge badge-info">neural-network</span> <span class="badge badge-info">tensorflow-addons</span> <span class="badge badge-info">python</span>', '<div id=pop91>tensorflow/addons</div>', 10, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/keras-team/keras/issues/11517 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Keras 2.0 release notes is misleading', '<span class="badge badge-info">deep-learning</span> <span class="badge badge-info">tensorflow</span> <span class="badge badge-info">neural-networks</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">python</span>', '<div id=pop92>keras-team/keras</div>', 8, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/polyaxon/polyaxon/issues/782 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Add spacy components', '<span class="badge badge-info">deep-learning</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">artificial-intelligence</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">reinforcement-learning</span> <span class="badge badge-info">kubernetes</span> <span class="badge badge-info">tensorflow</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">keras</span> <span class="badge badge-info">mxnet</span> <span class="badge badge-info">caffe</span> <span class="badge badge-info">ai</span> <span class="badge badge-info">ml</span> <span class="badge badge-info">k8s</span> <span class="badge badge-info">jupyter</span> <span class="badge badge-info">notebook</span> <span class="badge badge-info">jupyterlab</span> <span class="badge badge-info">pipelines</span> <span class="badge badge-info">workflow</span> <span class="badge badge-info">mlops</span>', '<div id=pop93>polyaxon/polyaxon</div>', 1, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/okfn-brasil/querido-diario/issues/203 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Texto do arquivo CONTRIBUTING.md está desatualizado', '<span class="badge badge-info">data-science</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">politics</span> <span class="badge badge-info">artificial-intelligence</span> <span class="badge badge-info">open-data</span> <span class="badge badge-info">civic-tech</span> <span class="badge badge-info">governments-gazettes</span> <span class="badge badge-info">govtech</span> <span class="badge badge-info">gazette-crawler</span> <span class="badge badge-info">spider</span> <span class="badge badge-info">hacktoberfest</span>', '<div id=pop94>okfn-brasil/querido-diario</div>', 5, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/vaexio/vaex/issues/932 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Audio Data Loading [FEATURE-REQUEST]', '<span class="badge badge-info">dataframe</span> <span class="badge badge-info">python</span> <span class="badge badge-info">bigdata</span> <span class="badge badge-info">tabular-data</span> <span class="badge badge-info">visualization</span> <span class="badge badge-info">memory-mapped-file</span> <span class="badge badge-info">hdf5</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">machinelearning</span>', '<div id=pop95>vaexio/vaex</div>', 2, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/okfn-brasil/querido-diario/issues/221 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Finish old spider PRs', '<span class="badge badge-info">data-science</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">politics</span> <span class="badge badge-info">artificial-intelligence</span> <span class="badge badge-info">open-data</span> <span class="badge badge-info">civic-tech</span> <span class="badge badge-info">governments-gazettes</span> <span class="badge badge-info">govtech</span> <span class="badge badge-info">gazette-crawler</span> <span class="badge badge-info">spider</span> <span class="badge badge-info">hacktoberfest</span>', '<div id=pop96>okfn-brasil/querido-diario</div>', 6, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/alan-turing-institute/sktime/issues/242 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Extend Tabularizer to TimeBinner', '<span class="badge badge-info">time-series</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">scikit-learn</span> <span class="badge badge-info">time-series-classification</span> <span class="badge badge-info">time-series-regression</span> <span class="badge badge-info">forecasting</span> <span class="badge badge-info">time-series-analysis</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">data-mining</span>', '<div id=pop97>alan-turing-institute/sktime</div>', 7, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/theislab/scanpy/issues/1174 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'pl.violin will not take "hue" kwarg for seaborn?', '<span class="badge badge-info">machine-learning</span> <span class="badge badge-info">data-science</span> <span class="badge badge-info">visualize-data</span> <span class="badge badge-info">transcriptomics</span> <span class="badge badge-info">bioinformatics</span> <span class="badge badge-info">scanpy</span> <span class="badge badge-info">anndata</span>', '<div id=pop98>theislab/scanpy</div>', 0, '<span class="badge badge-info">Python</span>'],
                ['<div><a href=https://github.com/mars-project/mars/issues/1340 target="_blank">🔗</a><span class="open_desc_modal"> 🔎</span></div>', 'Support {DataFrame,Series}.equals', '<span class="badge badge-info">python</span> <span class="badge badge-info">numpy</span> <span class="badge badge-info">tensor</span> <span class="badge badge-info">pandas</span> <span class="badge badge-info">dataframe</span> <span class="badge badge-info">machine-learning</span> <span class="badge badge-info">scikit-learn</span> <span class="badge badge-info">tensorflow</span> <span class="badge badge-info">pytorch</span> <span class="badge badge-info">xgboost</span> <span class="badge badge-info">lightgbm</span>', '<div id=pop99>mars-project/mars</div>', 1, '<span class="badge badge-info">Python</span>']
            ];
            var links = [
                ['https://github.com/couler-proj/couler/issues/100'],
                ['https://github.com/RaRe-Technologies/gensim/issues/2532'],
                ['https://github.com/mars-project/mars/issues/750'],
                ['https://github.com/GPflow/GPflow/issues/1516'],
                ['https://github.com/lightly-ai/lightly/issues/127'],
                ['https://github.com/mlflow/mlflow/issues/4202'],
                ['https://github.com/flyteorg/flyte/issues/524'],
                ['https://github.com/iterative/dvc/issues/2401'],
                ['https://github.com/koaning/scikit-lego/issues/292'],
                ['https://github.com/uber/petastorm/issues/203'],
                ['https://github.com/PyTorchLightning/pytorch-lightning/issues/5328'],
                ['https://github.com/replicate/keepsake/issues/302'],
                ['https://github.com/PyTorchLightning/pytorch-lightning/issues/5023'],
                ['https://github.com/dmlc/gluon-nlp/issues/631'],
                ['https://github.com/iver56/audiomentations/issues/50'],
                ['https://github.com/RaRe-Technologies/gensim/issues/1545'],
                ['https://github.com/unit8co/darts/issues/224'],
                ['https://github.com/Cloud-CV/EvalAI/issues/3297'],
                ['https://github.com/ray-project/ray/issues/5543'],
                ['https://github.com/awslabs/autogluon/issues/1043'],
                ['https://github.com/GPflow/GPflow/issues/1241'],
                ['https://github.com/ray-project/ray/issues/8050'],
                ['https://github.com/flyteorg/flyte/issues/392'],
                ['https://github.com/koaning/scikit-lego/issues/457'],
                ['https://github.com/quic/aimet/issues/344'],
                ['https://github.com/Neuraxio/Neuraxle/issues/303'],
                ['https://github.com/PyTorchLightning/pytorch-lightning/issues/4409'],
                ['https://github.com/ContinualAI/avalanche/issues/487'],
                ['https://github.com/catalyst-team/catalyst/issues/1160'],
                ['https://github.com/elyra-ai/elyra/issues/710'],
                ['https://github.com/skorch-dev/skorch/issues/291'],
                ['https://github.com/keras-team/keras/issues/8510'],
                ['https://github.com/ContinualAI/avalanche/issues/557'],
                ['https://github.com/scikit-learn/scikit-learn/issues/13117'],
                ['https://github.com/nilearn/nilearn/issues/1145'],
                ['https://github.com/ray-project/ray/issues/8450'],
                ['https://github.com/vwxyzjn/cleanrl/issues/29'],
                ['https://github.com/optuna/optuna/issues/517'],
                ['https://github.com/mlflow/mlflow/issues/4055'],
                ['https://github.com/theislab/scanpy/issues/1203'],
                ['https://github.com/vaexio/vaex/issues/912'],
                ['https://github.com/RaRe-Technologies/gensim/issues/1171'],
                ['https://github.com/orchest/orchest/issues/177'],
                ['https://github.com/nilearn/nilearn/issues/2412'],
                ['https://github.com/optuna/optuna/issues/1683'],
                ['https://github.com/flyteorg/flyte/issues/701'],
                ['https://github.com/ContinualAI/avalanche/issues/213'],
                ['https://github.com/flyteorg/flyte/issues/401'],
                ['https://github.com/dmlc/gluon-cv/issues/331'],
                ['https://github.com/optuna/optuna/issues/852'],
                ['https://github.com/online-ml/river/issues/400'],
                ['https://github.com/Trusted-AI/AIF360/issues/150'],
                ['https://github.com/dmlc/gluon-nlp/issues/1401'],
                ['https://github.com/tensorflow/addons/issues/258'],
                ['https://github.com/nilearn/nilearn/issues/1737'],
                ['https://github.com/Neuraxio/Neuraxle/issues/416'],
                ['https://github.com/PyTorchLightning/pytorch-lightning/issues/4536'],
                ['https://github.com/ourownstory/neural_prophet/issues/53'],
                ['https://github.com/GPflow/GPflow/issues/1604'],
                ['https://github.com/Cloud-CV/EvalAI/issues/1558'],
                ['https://github.com/nilearn/nilearn/issues/1397'],
                ['https://github.com/aimhubio/aim/issues/339'],
                ['https://github.com/couler-proj/couler/issues/84'],
                ['https://github.com/GPflow/GPflow/issues/1345'],
                ['https://github.com/dmlc/gluon-cv/issues/281'],
                ['https://github.com/yzhao062/pyod/issues/150'],
                ['https://github.com/larq/larq/issues/309'],
                ['https://github.com/flyteorg/flyte/issues/402'],
                ['https://github.com/ray-project/ray/issues/9384'],
                ['https://github.com/pykeen/pykeen/issues/82'],
                ['https://github.com/nilearn/nilearn/issues/2763'],
                ['https://github.com/iterative/dvc/issues/2613'],
                ['https://github.com/ray-project/ray/issues/10598'],
                ['https://github.com/couler-proj/couler/issues/32'],
                ['https://github.com/lightly-ai/lightly/issues/264'],
                ['https://github.com/alan-turing-institute/sktime/issues/745'],
                ['https://github.com/iterative/dvc/issues/2696'],
                ['https://github.com/catalyst-team/catalyst/issues/1161'],
                ['https://github.com/elyra-ai/elyra/issues/1066'],
                ['https://github.com/ContinualAI/avalanche/issues/331'],
                ['https://github.com/iterative/dvc/issues/1843'],
                ['https://github.com/mlflow/mlflow/issues/4077'],
                ['https://github.com/Neuraxio/Neuraxle/issues/210'],
                ['https://github.com/alan-turing-institute/sktime/issues/541'],
                ['https://github.com/mars-project/mars/issues/758'],
                ['https://github.com/ray-project/ray/issues/7722'],
                ['https://github.com/EducationalTestingService/skll/issues/688'],
                ['https://github.com/RaRe-Technologies/gensim/issues/1485'],
                ['https://github.com/flyteorg/flyte/issues/145'],
                ['https://github.com/fepegar/torchio/issues/81'],
                ['https://github.com/ourownstory/neural_prophet/issues/27'],
                ['https://github.com/tensorflow/addons/issues/337'],
                ['https://github.com/keras-team/keras/issues/11517'],
                ['https://github.com/polyaxon/polyaxon/issues/782'],
                ['https://github.com/okfn-brasil/querido-diario/issues/203'],
                ['https://github.com/vaexio/vaex/issues/932'],
                ['https://github.com/okfn-brasil/querido-diario/issues/221'],
                ['https://github.com/alan-turing-institute/sktime/issues/242'],
                ['https://github.com/theislab/scanpy/issues/1174'],
                ['https://github.com/mars-project/mars/issues/1340']
            ];
            var repo_desc = [
                ['Unified Interface for Constructing and Managing Workflows on different workflow engines, such as Argo Workflows, Tekton Pipelines, and Apache Airflow.'],
                ['Topic Modelling for Humans'],
                ['Mars is a tensor-based unified framework for large-scale data computation which scales Numpy, pandas, Scikit-learn and Python functions.'],
                ['Gaussian processes in TensorFlow'],
                ['A python library for self-supervised learning on images.'],
                ['Open source platform for the machine learning lifecycle'],
                ['Accelerate your ML and Data workflows to production. Flyte is a production grade orchestration system for your Data and ML workloads. It has been battle tested at Lyft, Spotify, freenome and others and truly open-source.'],
                ['🦉Data Version Control | Git for Data & Models'],
                ['Extra blocks for scikit-learn pipelines.'],
                ['Petastorm library enables single machine or distributed training and evaluation of deep learning models from datasets in Apache Parquet format. It supports ML frameworks such as Tensorflow, Pytorch, and PySpark and can be used from pure Python code.'],
                ['The lightweight PyTorch wrapper for high-performance AI research. Scale your models, not the boilerplate.'],
                ['Version control for machine learning'],
                ['The lightweight PyTorch wrapper for high-performance AI research. Scale your models, not the boilerplate.'],
                ['NLP made easy'],
                ['A Python library for audio data augmentation. Inspired by albumentations. Useful for machine learning.'],
                ['Topic Modelling for Humans'],
                ['A python library for easy manipulation and forecasting of time series.'],
                [':cloud: :rocket: :bar_chart: :chart_with_upwards_trend: Evaluating state of the art in AI'],
                ['An open source framework that provides a simple, universal API for building distributed applications. Ray is packaged with RLlib, a scalable reinforcement learning library, and Tune, a scalable hyperparameter tuning library.'],
                ['AutoGluon: AutoML for Text, Image, and Tabular Data'],
                ['Gaussian processes in TensorFlow'],
                ['An open source framework that provides a simple, universal API for building distributed applications. Ray is packaged with RLlib, a scalable reinforcement learning library, and Tune, a scalable hyperparameter tuning library.'],
                ['Accelerate your ML and Data workflows to production. Flyte is a production grade orchestration system for your Data and ML workloads. It has been battle tested at Lyft, Spotify, freenome and others and truly open-source.'],
                ['Extra blocks for scikit-learn pipelines.'],
                ['AIMET is a library that provides advanced quantization and compression techniques for trained neural network models.'],
                ['A Sklearn-like Framework for Hyperparameter Tuning and AutoML in Deep Learning projects. Finally have the right abstractions and design patterns to properly do AutoML. Let your pipeline steps have hyperparameter spaces. Enable checkpoints to cut duplicate calculations. Go from research to production environment easily.'],
                ['The lightweight PyTorch wrapper for high-performance AI research. Scale your models, not the boilerplate.'],
                ['Avalanche: an End-to-End Library for Continual Learning.'],
                ['Accelerated deep learning R&D'],
                ['Elyra extends JupyterLab Notebooks with an AI centric approach.'],
                ['A scikit-learn compatible neural network library that wraps PyTorch'],
                ['Deep Learning for humans'],
                ['Avalanche: an End-to-End Library for Continual Learning.'],
                ['scikit-learn: machine learning in Python'],
                ['Machine learning for NeuroImaging in Python'],
                ['An open source framework that provides a simple, universal API for building distributed applications. Ray is packaged with RLlib, a scalable reinforcement learning library, and Tune, a scalable hyperparameter tuning library.'],
                ['High-quality single file implementation of Deep Reinforcement Learning algorithms with research-friendly features'],
                ['A hyperparameter optimization framework'],
                ['Open source platform for the machine learning lifecycle'],
                ['Single-Cell Analysis in Python. Scales to >1M cells.'],
                ['Out-of-Core hybrid Apache Arrow/NumPy DataFrame for Python, ML, visualize and explore big tabular data at a billion rows per second 🚀'],
                ['Topic Modelling for Humans'],
                ['A new kind of IDE for Data Science.'],
                ['Machine learning for NeuroImaging in Python'],
                ['A hyperparameter optimization framework'],
                ['Accelerate your ML and Data workflows to production. Flyte is a production grade orchestration system for your Data and ML workloads. It has been battle tested at Lyft, Spotify, freenome and others and truly open-source.'],
                ['Avalanche: an End-to-End Library for Continual Learning.'],
                ['Accelerate your ML and Data workflows to production. Flyte is a production grade orchestration system for your Data and ML workloads. It has been battle tested at Lyft, Spotify, freenome and others and truly open-source.'],
                ['Gluon CV Toolkit'],
                ['A hyperparameter optimization framework'],
                ['🌊 Online machine learning in Python'],
                ['A comprehensive set of fairness metrics for datasets and machine learning models, explanations for these metrics, and algorithms to mitigate bias in datasets and models.'],
                ['NLP made easy'],
                ['Useful extra functionality for TensorFlow 2.x maintained by SIG-addons'],
                ['Machine learning for NeuroImaging in Python'],
                ['A Sklearn-like Framework for Hyperparameter Tuning and AutoML in Deep Learning projects. Finally have the right abstractions and design patterns to properly do AutoML. Let your pipeline steps have hyperparameter spaces. Enable checkpoints to cut duplicate calculations. Go from research to production environment easily.'],
                ['The lightweight PyTorch wrapper for high-performance AI research. Scale your models, not the boilerplate.'],
                ['NeuralProphet - A simple forecasting model based on Neural Networks in PyTorch'],
                ['Gaussian processes in TensorFlow'],
                [':cloud: :rocket: :bar_chart: :chart_with_upwards_trend: Evaluating state of the art in AI'],
                ['Machine learning for NeuroImaging in Python'],
                ['Aim — a super-easy way to record, search and compare 1000s of ML training runs'],
                ['Unified Interface for Constructing and Managing Workflows on different workflow engines, such as Argo Workflows, Tekton Pipelines, and Apache Airflow.'],
                ['Gaussian processes in TensorFlow'],
                ['Gluon CV Toolkit'],
                ["(JMLR'19) A Python Toolbox for Scalable Outlier Detection (Anomaly Detection)"],
                ['An Open-Source Library for Training Binarized Neural Networks'],
                ['Accelerate your ML and Data workflows to production. Flyte is a production grade orchestration system for your Data and ML workloads. It has been battle tested at Lyft, Spotify, freenome and others and truly open-source.'],
                ['An open source framework that provides a simple, universal API for building distributed applications. Ray is packaged with RLlib, a scalable reinforcement learning library, and Tune, a scalable hyperparameter tuning library.'],
                ['🤖 A Python library for learning and evaluating knowledge graph embeddings '],
                ['Machine learning for NeuroImaging in Python'],
                ['🦉Data Version Control | Git for Data & Models'],
                ['An open source framework that provides a simple, universal API for building distributed applications. Ray is packaged with RLlib, a scalable reinforcement learning library, and Tune, a scalable hyperparameter tuning library.'],
                ['Unified Interface for Constructing and Managing Workflows on different workflow engines, such as Argo Workflows, Tekton Pipelines, and Apache Airflow.'],
                ['A python library for self-supervised learning on images.'],
                ['A unified framework for machine learning with time series'],
                ['🦉Data Version Control | Git for Data & Models'],
                ['Accelerated deep learning R&D'],
                ['Elyra extends JupyterLab Notebooks with an AI centric approach.'],
                ['Avalanche: an End-to-End Library for Continual Learning.'],
                ['🦉Data Version Control | Git for Data & Models'],
                ['Open source platform for the machine learning lifecycle'],
                ['A Sklearn-like Framework for Hyperparameter Tuning and AutoML in Deep Learning projects. Finally have the right abstractions and design patterns to properly do AutoML. Let your pipeline steps have hyperparameter spaces. Enable checkpoints to cut duplicate calculations. Go from research to production environment easily.'],
                ['A unified framework for machine learning with time series'],
                ['Mars is a tensor-based unified framework for large-scale data computation which scales Numpy, pandas, Scikit-learn and Python functions.'],
                ['An open source framework that provides a simple, universal API for building distributed applications. Ray is packaged with RLlib, a scalable reinforcement learning library, and Tune, a scalable hyperparameter tuning library.'],
                ['SciKit-Learn Laboratory (SKLL) makes it easy to run machine learning experiments.'],
                ['Topic Modelling for Humans'],
                ['Accelerate your ML and Data workflows to production. Flyte is a production grade orchestration system for your Data and ML workloads. It has been battle tested at Lyft, Spotify, freenome and others and truly open-source.'],
                ['Medical image preprocessing and augmentation toolkit for deep learning'],
                ['NeuralProphet - A simple forecasting model based on Neural Networks in PyTorch'],
                ['Useful extra functionality for TensorFlow 2.x maintained by SIG-addons'],
                ['Deep Learning for humans'],
                ['Machine Learning Platform for Kubernetes (MLOps tools for experimentation and automation)'],
                ['📰 Brazilian government gazettes, accessible to everyone.'],
                ['Out-of-Core hybrid Apache Arrow/NumPy DataFrame for Python, ML, visualize and explore big tabular data at a billion rows per second 🚀'],
                ['📰 Brazilian government gazettes, accessible to everyone.'],
                ['A unified framework for machine learning with time series'],
                ['Single-Cell Analysis in Python. Scales to >1M cells.'],
                ['Mars is a tensor-based unified framework for large-scale data computation which scales Numpy, pandas, Scikit-learn and Python functions.']
            ];
            var stars = [
                [444],
                [12007],
                [2110],
                [1432],
                [782],
                [9243],
                [1365],
                [7806],
                [491],
                [1137],
                [13271],
                [1457],
                [13271],
                [2270],
                [495],
                [12007],
                [839],
                [1115],
                [15791],
                [3148],
                [1432],
                [15791],
                [1365],
                [491],
                [489],
                [405],
                [13271],
                [376],
                [2546],
                [914],
                [3927],
                [51109],
                [376],
                [45594],
                [728],
                [15791],
                [397],
                [4494],
                [9243],
                [883],
                [6073],
                [12007],
                [730],
                [728],
                [4494],
                [1365],
                [376],
                [1365],
                [4704],
                [4494],
                [1568],
                [1362],
                [2270],
                [1271],
                [728],
                [405],
                [13271],
                [1216],
                [1432],
                [1115],
                [728],
                [1066],
                [444],
                [1432],
                [4704],
                [4436],
                [429],
                [1365],
                [15791],
                [399],
                [728],
                [7806],
                [15791],
                [444],
                [782],
                [3921],
                [7806],
                [2546],
                [914],
                [376],
                [7806],
                [9243],
                [405],
                [3921],
                [2110],
                [15791],
                [526],
                [12007],
                [1365],
                [777],
                [1216],
                [1271],
                [51109],
                [2806],
                [690],
                [6073],
                [690],
                [3921],
                [883],
                [2110]
            ];

            var sp = $('#spreadsheet').jexcel({
                data: data,
                csvHeaders: false,
                search: false,
                tableOverflow: true,
                tableWidth: "96vw",
                tableHeight: "80vh",
                defaultColWidth: "100vw",
                minDimensions: [7, 50],
                rowResize: true,
                colHeaders: [
                    '',
                    'Issue',
                    'Topics',
                    'Repository',
                    '# Comments',
                    'Language',
                    '',
                ],
                colWidths: [70, 700, 1000, 200, 110, 100, 2000],
                colAlignments: ['left', 'left', 'left', 'left', 'left', 'left', 'left'],
                columns: [{
                    type: 'html',
                    readOnly: true
                }, {
                    type: 'html',
                    readOnly: true
                }, {
                    type: 'html',
                    readOnly: true
                }, {
                    type: 'html',
                    readOnly: true
                }, {
                    type: 'html',
                    readOnly: true
                }, {
                    type: 'html',
                    readOnly: true
                }, {
                    type: 'html',
                    readOnly: true
                }, ]
            });

            var data_all;
            data_all = sp.getData();

            $(document).ready(function() {

                $(function() {
                    $('[data-toggle="popover"]').popover()
                });

                for (i = 0; i < repo_desc.length; i++) {
                    $('#pop' + i).popover({
                        trigger: 'hover',
                        content: repo_desc[i][0] + '\n' + '⭐' + stars[i].toLocaleString()
                    });
                };

                sp.headers[0].innerHTML = '';
                sp.headers[6].innerHTML = '';
                document.querySelector(".jexcel_content").style.removeProperty("box-shadow");

            });

            var converter = new showdown.Converter();

            $('.open_desc_modal').click(function() {

                var cell = sp.selectedCell;
                var rowix = cell[1];
                var rowData = sp.getRowData(rowix);
                var description = converter.makeHtml(desc[rowix][0]);

                document.getElementById("mtitle").innerHTML = rowData[1];
                document.getElementById("mbody").innerHTML = (
                    '<h6><small class="text-muted" id="msubcat">Link</small><h6>' +
                    '<p style="padding-bottom:30px;font-weight:lighter"><a href="' + links[rowix] + '", target="_blank">' + links[rowix] + '</a></p>' +
                    '<h6><small class="text-muted" id="msubcat">Topics</small><h6>' +
                    '<p style="padding-bottom:30px;">' + rowData[2] + '</p>' +
                    '<h6><small class="text-muted" id="msubcat">Repository</small><h6>' +
                    '<p style="padding-bottom:5px;font-weight:lighter">' + rowData[3].replace(/(<([^>]+)>)/gi, "") + '&nbsp;&nbsp;&nbsp;⭐ ' + stars[rowix].toLocaleString() + '</p>' +
                    '<p style="padding-bottom:30px;font-weight:lighter">' + repo_desc[rowix] + '\n' + '</p>' +
                    '<h6><small class="text-muted" id="msubcat">Language</small><h6>' +
                    '<p style="padding-bottom:30px;">' + rowData[5] + '</p>' +
                    '<h6><small class="text-muted" id="msubcat"># Comments</small><h6>' +
                    '<p style="padding-bottom:30px;font-weight:lighter">' + rowData[4] + '</p>' +
                    '<h6><small class="text-muted" id="msubcat">Description</small><h6>' +
                    '<div style="padding-bottom:30px;font-weight:lighter;padding-top:-30px;">' + description + '</div>'
                )

                $('#desc_modal').modal({
                    'show': true,
                });

            });
        </script>

        <script>
        </script>

</body>

</html>